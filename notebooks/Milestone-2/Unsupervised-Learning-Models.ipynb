{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Task 2.7: K-Means Clustering Implementation\n",
    "\n",
    "## Objective\n",
    "The goal of this task is to group Airbnb listings into 3 clusters (Excellent, Fair, and Poor Value) using an unsupervised approach and validate these clusters using Elbow and Silhouette methods.\n",
    "\n",
    "## Understanding Key Metrics\n",
    "\n",
    "Since this is an unsupervised task, we use specific metrics to evaluate how well our algorithm performs without seeing the ground truth labels:\n",
    "\n",
    "1. **Purity Score:** - Measures the extent to which each cluster contains a single class. A purity of 1 indicates perfect clustering.\n",
    "2. **Adjusted Rand Index (ARI):** - Measures the similarity between two clusterings (predicted vs actual) while adjusting for chance. Range is -1 to 1, where 1 is a perfect match.\n",
    "3. **Silhouette Score:** - Measures how similar an object is to its own cluster compared to other clusters. Range is -1 to 1, where higher values indicate well-separated clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Data Discovery\n",
    "In this step, we import the required libraries and locate the preprocessed dataset in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "# Define the relative path to the data folder\n",
    "data_folder = \"../../data/\"\n",
    "\n",
    "# List all files to identify the correct dataset\n",
    "print(\"Searching for data files in:\", os.path.abspath(data_folder))\n",
    "try:\n",
    "    data_files = os.listdir(data_folder)\n",
    "    print(\"Files found in data directory:\")\n",
    "    for file in data_files:\n",
    "        print(f\"- {file}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The system cannot find the specified data path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 2: Data Verification\n",
    "Now, we will examine the 'processed' index to find the processed version of our dataset for our process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the contents of the processed folder\n",
    "processed_folder = \"../../data/processed/\"\n",
    "\n",
    "print(\"Files in processed directory:\")\n",
    "try:\n",
    "    processed_files = os.listdir(processed_folder)\n",
    "    for file in processed_files:\n",
    "        print(f\"- {file}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: processed folder not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 3: Loading the Dataset\n",
    "We will load the pre-scaled training features and their corresponding labels. The features will be used for clustering, while the labels will serve as the ground truth for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the specific files\n",
    "x_train_path = os.path.join(processed_folder, \"X_train_scaled.csv\")\n",
    "y_train_path = os.path.join(processed_folder, \"y_train.csv\")\n",
    "\n",
    "# Loading the datasets\n",
    "X_train = pd.read_csv(x_train_path)\n",
    "y_train = pd.read_csv(y_train_path)\n",
    "\n",
    "# Verification\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Displaying the first few rows of features\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Step 4: K-Means Implementation (K=3)\n",
    "In this step, we initialize the K-Means algorithm with 3 clusters. We use the 'k-means++' initialization method to ensure better convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize K-Means with K=3\n",
    "# random_state is set to 42 for reproducibility\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42, n_init=10)\n",
    "\n",
    "# Fitting the model to the scaled data\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Assigning the cluster labels to our data\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "print(\"K-Means clustering completed.\")\n",
    "print(\"Cluster assignments for the first 10 samples:\")\n",
    "print(cluster_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Step 5: Elbow Method for Optimal K\n",
    "The Elbow Method helps us validate if K=3 is a reasonable choice by plotting the \"Within-Cluster Sum of Squares\" (Inertia) for different values of K. We look for a \"bend\" in the graph, similar to an elbow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the inertia (within-cluster sum of squares) for each K\n",
    "inertia_values = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "# Loop through different K values from 1 to 10\n",
    "for k in k_range:\n",
    "    kmeans_model = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)\n",
    "    kmeans_model.fit(X_train)\n",
    "    inertia_values.append(kmeans_model.inertia_)\n",
    "\n",
    "# Plotting the Elbow Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia_values, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (WCSS)')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Interpretation of the Elbow Plot\n",
    "\n",
    "The Elbow Method provides a visual representation of the **Within-Cluster Sum of Squares (Inertia)** as a function of the number of clusters (K).\n",
    "\n",
    "### Observations:\n",
    "1. **Diminishing Returns:** As $K$ increases, the inertia consistently decreases because the clusters become smaller and the points are closer to their respective centroids.\n",
    "2. **The \"Elbow\" Point:** Looking at the graph, we observe a significant \"bend\" or \"elbow\" typically between **$K=2$** and **$K=3$**. This point indicates that adding more clusters beyond this value does not provide a substantial decrease in inertia.\n",
    "3. **Consistency with Ground Truth:** Since our target labels (Excellent, Fair, and Poor Value) naturally form 3 categories, selecting **$K=3$** is mathematically justifiable as it aligns with the business logic of our project while still being near the elbow point.\n",
    "\n",
    "**Conclusion:** We will proceed with $K=3$ for our clustering analysis, as it offers a good balance between model simplicity and data representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 6: Silhouette Analysis for K=3\n",
    "While the Elbow Method looks at distances within clusters, the Silhouette Score measures how well-separated the clusters are from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Silhouette Score for our K=3 model\n",
    "score = silhouette_score(X_train, cluster_labels)\n",
    "\n",
    "print(f\"Silhouette Score for K=3: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Interpretation of the Silhouette Score\n",
    "\n",
    "The Silhouette Score is a metric used to calculate the goodness of a clustering technique. Its value ranges from -1 to 1.\n",
    "\n",
    "### Analysis of Result:\n",
    "- **Silhouette Score:** 0.7800\n",
    "- **Strength of Structure:** According to standard clustering interpretation, a score above 0.70 indicates a **strong structure**. This means the clusters are well-defined, dense, and clearly separated from each other.\n",
    "- **Project Insight:** This high score suggests that the features used (after scaling) have a high discriminatory power.\n",
    "\n",
    "**Conclusion:** The K-Means algorithm has successfully identified 3 distinct groups within the dataset. The high silhouette value confirms that our 3-cluster assumption is mathematically robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Step 7: Performance Evaluation against True Labels\n",
    "\n",
    "In this final step, we compare the clusters generated by K-Means with the actual categories (Excellent, Fair, and Poor Value). \n",
    "\n",
    "We will use two main metrics:\n",
    "1. **Adjusted Rand Index (ARI):** To measure the similarity between the two assignments while accounting for chance.\n",
    "2. **Purity Score:** To see how \"pure\" each cluster is in terms of containing a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Step 1: Assigning y_true from the encoded column (integer format)\n",
    "y_true = y_train['value_encoded'].values\n",
    "\n",
    "# Step 2: Recalculating Adjusted Rand Index (ARI)\n",
    "ari_score = adjusted_rand_score(y_true, cluster_labels)\n",
    "print(f\"Adjusted Rand Index (ARI): {ari_score:.4f}\")\n",
    "\n",
    "# Step 3: Purity Calculation\n",
    "def calculate_purity(y_true, y_pred):\n",
    "    # Generating the contingency matrix (cross-tabulation matrix)\n",
    "    contingency_matrix = confusion_matrix(y_true, y_pred)\n",
    "    # Summing the maximum matches in each cluster\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "purity = calculate_purity(y_true, cluster_labels)\n",
    "print(f\"Purity Score: {purity:.4f}\")\n",
    "\n",
    "# Step 4: Cross-tabulation to see the mapping\n",
    "# This table shows which cluster (0, 1, 2) matches which encoded value (0, 1, 2)\n",
    "comparison_df = pd.DataFrame({'Actual_Encoded': y_true, 'Cluster_Predicted': cluster_labels})\n",
    "crosstab = pd.crosstab(comparison_df['Actual_Encoded'], comparison_df['Cluster_Predicted'])\n",
    "\n",
    "print(\"\\nCross-tabulation Table:\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Step 8: Final Clustering Performance Results\n",
    "\n",
    "The cross-tabulation table below shows the distribution of ground truth labels (Actual_Encoded) across the clusters discovered by K-Means.\n",
    "\n",
    "### Performance Summary:\n",
    "| Metric | Value | Interpretation |\n",
    "| :--- | :--- | :--- |\n",
    "| **Silhouette Score** | 0.7800 | Very Strong Separation |\n",
    "| **Adjusted Rand Index (ARI)** | 0.0048 | No Correlation with Labels |\n",
    "| **Purity Score** | 0.3652 | Near-Random Assignment |\n",
    "\n",
    "### Cross-tabulation Table:\n",
    "| Actual \\ Cluster | Cluster 0 | Cluster 1 | Cluster 2 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **0 (Poor_Value)** | 1879 | 1705 | 1673 |\n",
    "| **1 (Fair_Value)** | 2339 | 1557 | 1522 |\n",
    "| **2 (Excellent_Value)** | 2439 | 1566 | 1249 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Deep Dive into Clustering Results\n",
    "\n",
    "We are observing a significant gap between the **Silhouette Score (0.78)** and the **ARI (0.0048)**. This leads to several technical conclusions:\n",
    "\n",
    "1. **Feature Dominance:** The K-Means algorithm found 3 very distinct clusters. However, these clusters are formed based on features that do not represent \"Value Categories.\" For example, the clusters might be grouping listings by **Geography** (San Francisco vs. San Diego) or **Room Type** instead of the FP Score.\n",
    "2. **The \"Unsupervised\" Reality:** Since K-Means does not see the labels, it optimizes for spatial distance. In our feature space, the listings in \"Excellent Value\" are spatially mixed with \"Poor Value\" listings.\n",
    "3. **Data Overlap:** The cross-tabulation table shows that each cluster contains a nearly equal number of Poor, Fair, and Excellent listings. This confirms that our current feature set, when used in an unsupervised manner, cannot distinguish between the value categories.\n",
    "\n",
    "**Action Item:** In the upcoming tasks (T2.11 PCA), we should investigate which features are driving these 0.78-score clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Task 2.8: Hierarchical Clustering Analysis\n",
    "\n",
    "## Objective\n",
    "The goal of this task is to perform Agglomerative Hierarchical Clustering using three different linkage methods: **Ward, Average, and Complete**. We will visualize the data structure using a Dendrogram and evaluate the results using Silhouette and ARI metrics.\n",
    "\n",
    "## Linkage Methods Explained:\n",
    "1. **Ward:** Minimizes the variance of the clusters being merged. It usually creates clusters of similar sizes.\n",
    "2. **Average:** Uses the average distance between all points in two clusters.\n",
    "3. **Complete:** Uses the maximum distance between points in two clusters (farthest neighbor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Step 1: Dendrogram Visualization (Sampling)\n",
    "Hierarchical clustering is computationally expensive. Therefore, we will use a sample of 2,000 rows to visualize the Dendrogram and understand the hierarchical structure of our Airbnb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sampling 2,000 rows for visualization purposes\n",
    "X_sample = X_train.sample(n=2000, random_state=42)\n",
    "\n",
    "# Computing the linkage matrix using 'ward' method\n",
    "Z = linkage(X_sample, method='ward')\n",
    "\n",
    "# Plotting the Dendrogram\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title('Hierarchical Clustering Dendrogram (Ward Linkage - Sampled)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z, truncate_mode='lastp', p=30, leaf_rotation=90., leaf_font_size=10., show_contracted=True)\n",
    "plt.axhline(y=150, color='r', linestyle='--') # Example threshold line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Step 2: Training Agglomerative Models (K=3)\n",
    "We will now train three separate Hierarchical models on the full training set using Ward, Average, and Complete linkage methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Initializing models with K=3\n",
    "linkage_methods = ['ward', 'average', 'complete']\n",
    "results = {}\n",
    "\n",
    "for method in linkage_methods:\n",
    "    print(f\"Running Agglomerative Clustering with {method} linkage...\")\n",
    "    model = AgglomerativeClustering(n_clusters=3, linkage=method)\n",
    "    labels = model.fit_predict(X_train)\n",
    "    \n",
    "    # Calculate scores\n",
    "    s_score = silhouette_score(X_train, labels)\n",
    "    a_score = adjusted_rand_score(y_true, labels)\n",
    "    \n",
    "    results[method] = {'Silhouette': s_score, 'ARI': a_score, 'Labels': labels}\n",
    "    print(f\"Finished {method}. Silhouette: {s_score:.4f}, ARI: {a_score:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame for easy comparison\n",
    "df_results = pd.DataFrame(results).T.drop(columns=['Labels'])\n",
    "print(\"\\nFinal Comparison Table:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Interpretation of Hierarchical Clustering Results\n",
    "\n",
    "After testing three different linkage methods, we observe a consistent pattern that mirrors our K-Means results.\n",
    "\n",
    "### 1. High Silhouette Scores (>0.71)\n",
    "All three methods (Ward, Average, Complete) yielded very high Silhouette scores. This confirms that the data has a **strong intrinsic structure**. The algorithm is successfully finding distinct groups that are spatially far apart from each other.\n",
    "\n",
    "### 2. Low ARI Scores (~0.005)\n",
    "Despite the strong physical separation of the clusters, the **Adjusted Rand Index (ARI)** remains near zero. This indicates that the natural groupings in the data do not correspond to our 'Excellent', 'Fair', or 'Poor' value categories.\n",
    "\n",
    "### Comparison Table:\n",
    "- **Average Linkage** provided the highest Silhouette score (0.7793), suggesting it found the most compact and well-separated clusters.\n",
    "- **Ward Linkage** provided the (slightly) best ARI (0.0055), though it is still not statistically significant.\n",
    "\n",
    "**Final Conclusion:** The features that dominate the clustering process are likely related to listing characteristics (e.g., location, property type) rather than the price-quality relationship we defined in the target labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Task 2.9: DBSCAN Clustering\n",
    "\n",
    "## Objective\n",
    "The goal of this task is to implement **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**. Unlike K-Means, DBSCAN does not require us to specify the number of clusters (K) in advance. It finds clusters based on the density of data points and identifies outliers as \"noise.\"\n",
    "\n",
    "## Key Hyperparameters:\n",
    "1. **Epsilon (eps):** The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "2. **Min_samples:** The number of samples in a neighborhood for a point to be considered as a core point.\n",
    "\n",
    "## Evaluation Strategy:\n",
    "Since DBSCAN identifies outliers (labeled as -1), we will analyze the \"noise ratio\" and compare the resulting clusters with our Ground Truth categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Step 1: Calculate the distance to the nearest n_neighbors\n",
    "# min_samples is typically set to 2 * dimensions. \n",
    "# For now, let's use 10 as a starting point for neighbors.\n",
    "neighbors = NearestNeighbors(n_neighbors=10)\n",
    "neighbors_fit = neighbors.fit(X_train)\n",
    "distances, indices = neighbors_fit.kneighbors(X_train)\n",
    "\n",
    "# Step 2: Sort and plot the distances\n",
    "distances = np.sort(distances[:, 9], axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.title('K-Distance Graph for Epsilon Estimation')\n",
    "plt.xlabel('Data Points sorted by distance')\n",
    "plt.ylabel('Epsilon (Distance to 10th Nearest Neighbor)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Step 2: Running DBSCAN Clustering\n",
    "Based on the K-Distance graph, the \"elbow\" starts to form around $0.1 \\times 10^{16}$. We will use this as our starting **eps** value. We set **min_samples=20** to ensure that a group must have a decent density to be considered a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Initializing DBSCAN\n",
    "# We use the estimated epsilon from the graph\n",
    "# Note: Since the scale is 1e16, we use 1e15 as a starting point (0.1e16)\n",
    "epsilon_val = 1e15 \n",
    "min_samples_val = 20\n",
    "\n",
    "dbscan = DBSCAN(eps=epsilon_val, min_samples=min_samples_val)\n",
    "\n",
    "# Fitting the model\n",
    "dbscan_labels = dbscan.fit_predict(X_train)\n",
    "\n",
    "# Checking the number of clusters found (excluding noise)\n",
    "# Noise points are labeled as -1\n",
    "n_clusters_ = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise_ = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"Estimated number of clusters: {n_clusters_}\")\n",
    "print(f\"Estimated number of noise points: {n_noise_} (out of {len(X_train)})\")\n",
    "print(f\"Noise ratio: {n_noise_ / len(X_train):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Interpretation of Initial DBSCAN Results\n",
    "\n",
    "The initial run with $eps=1e15$ and $min\\_samples=20$ yielded **144 clusters** and a **11.92% noise ratio**.\n",
    "\n",
    "### Observations:\n",
    "1. **High Fragmentation:** The large number of clusters suggests that the chosen epsilon is too small, or the data contains many small, highly dense pockets that do not align with our 3 broad value categories.\n",
    "2. **Outlier Detection:** DBSCAN successfully identified 1,899 listings as noise. These are listings that are spatially isolated in the feature space.\n",
    "3. **Comparison:** While K-Means forced every point into 3 clusters, DBSCAN reveals that the data structure is actually much more fragmented when viewed through the lens of density.\n",
    "\n",
    "**Next Step:** We will perform a brief hyperparameter tuning to see if we can merge these small clusters into larger, more meaningful groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a larger Epsilon to merge fragmented clusters\n",
    "# We will try a few values and observe the cluster count\n",
    "test_epsilons = [2e15, 5e15, 8e15]\n",
    "\n",
    "for e in test_epsilons:\n",
    "    temp_dbscan = DBSCAN(eps=e, min_samples=30) # Increased min_samples for more robust clusters\n",
    "    temp_labels = temp_dbscan.fit_predict(X_train)\n",
    "    \n",
    "    n_clus = len(set(temp_labels)) - (1 if -1 in temp_labels else 0)\n",
    "    n_noi = list(temp_labels).count(-1)\n",
    "    \n",
    "    print(f\"Eps: {e:.1e} | Clusters: {n_clus} | Noise: {n_noi} ({n_noi/len(X_train):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Final DBSCAN Model Selection and Evaluation\n",
    "\n",
    "After hyperparameter tuning, we selected **Epsilon = 5e15** and **Min_samples = 30**. \n",
    "\n",
    "### Rationale:\n",
    "- **Stability:** This configuration stabilized the cluster count to 2 main groups, significantly reducing the fragmentation (51 clusters) seen at lower epsilon values.\n",
    "- **Noise Control:** The noise ratio is extremely low (0.08%), meaning almost all listings belong to a dense region.\n",
    "- **Insight:** The fact that DBSCAN consistently finds 2 clusters instead of 3 suggests that the ground truth labels do not follow a density-based distribution in the current feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final DBSCAN with the best parameters found\n",
    "final_dbscan = DBSCAN(eps=5e+15, min_samples=30)\n",
    "dbscan_labels_final = final_dbscan.fit_predict(X_train)\n",
    "\n",
    "# Metrics calculation\n",
    "db_ari = adjusted_rand_score(y_true, dbscan_labels_final)\n",
    "db_purity = calculate_purity(y_true, dbscan_labels_final) # Using our previous function\n",
    "\n",
    "print(f\"DBSCAN Final Results (Eps=5e15):\")\n",
    "print(f\"Adjusted Rand Index (ARI): {db_ari:.4f}\")\n",
    "print(f\"Purity Score: {db_purity:.4f}\")\n",
    "\n",
    "# Cross-tabulation to see how the 2 clusters align with 3 labels\n",
    "dbscan_comparison = pd.DataFrame({'Actual': y_true, 'DBSCAN_Cluster': dbscan_labels_final})\n",
    "print(\"\\nCross-tabulation (Actual vs DBSCAN Cluster):\")\n",
    "print(pd.crosstab(dbscan_comparison['Actual'], dbscan_comparison['DBSCAN_Cluster']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Final Analysis of DBSCAN Performance\n",
    "\n",
    "The results from DBSCAN (Eps=5e15) further confirm the findings from previous models.\n",
    "\n",
    "### Key Observations:\n",
    "- **Low ARI (0.0050):** Similar to K-Means, DBSCAN's clusters do not align with our ground truth categories. \n",
    "- **Purity (0.3652):** The purity score remains low, as each discovered cluster contains a roughly equal distribution of all three value categories.\n",
    "- **Cluster Logic:** The Cross-tabulation shows that DBSCAN found two massive clusters (Cluster 0 and Cluster 1). This suggests that the dense regions of the data are split into two major parts, which might represent broad listing types or major geographical divides.\n",
    "\n",
    "**Conclusion:** Density-based clustering is not sufficient to distinguish between Excellent, Fair, and Poor value categories in the current feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Task 2.10: Gaussian Mixture Model (GMM)\n",
    "\n",
    "## Objective\n",
    "The goal is to implement Gaussian Mixture Models (GMM) to perform probabilistic clustering. We will use **BIC (Bayesian Information Criterion)** and **AIC (Akaike Information Criterion)** to determine the optimal number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Step 1: Model Selection using BIC and AIC\n",
    "n_components = range(1, 11)\n",
    "bics = []\n",
    "aics = []\n",
    "\n",
    "for n in n_components:\n",
    "    gmm = GaussianMixture(n_components=n, random_state=42)\n",
    "    gmm.fit(X_train)\n",
    "    bics.append(gmm.bic(X_train))\n",
    "    aics.append(gmm.aic(X_train))\n",
    "\n",
    "# Step 2: Plotting BIC and AIC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_components, bics, label='BIC', marker='o')\n",
    "plt.plot(n_components, aics, label='AIC', marker='o')\n",
    "plt.title('GMM Model Selection: BIC & AIC')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing GMM with 3 components as per our target categories\n",
    "final_gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "gmm_labels = final_gmm.fit_predict(X_train)\n",
    "\n",
    "# Probabilities: Every row will have 3 probability values summing to 1\n",
    "gmm_probs = final_gmm.predict_proba(X_train)\n",
    "\n",
    "# Metrics Calculation\n",
    "gmm_ari = adjusted_rand_score(y_true, gmm_labels)\n",
    "gmm_purity = calculate_purity(y_true, gmm_labels)\n",
    "\n",
    "print(f\"GMM Results (n_components=3):\")\n",
    "print(f\"Adjusted Rand Index (ARI): {gmm_ari:.4f}\")\n",
    "print(f\"Purity Score: {gmm_purity:.4f}\")\n",
    "\n",
    "# Cross-tabulation\n",
    "gmm_comparison = pd.DataFrame({'Actual': y_true, 'GMM_Cluster': gmm_labels})\n",
    "print(\"\\nCross-tabulation (Actual vs GMM Cluster):\")\n",
    "print(pd.crosstab(gmm_comparison['Actual'], gmm_comparison['GMM_Cluster']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Interpretation of GMM Results\n",
    "\n",
    "Gaussian Mixture Models (GMM) outperformed previous \"hard\" clustering methods, providing the highest **ARI (0.0174)** and **Purity (0.3987)** so far.\n",
    "\n",
    "### Analysis:\n",
    "1. **Probabilistic Advantage:** Unlike K-Means, GMM allows for elliptical cluster shapes and overlapping boundaries. The slight increase in ARI suggests that our value categories are not separated by rigid distances but rather follow a more fluid, probabilistic distribution.\n",
    "2. **Cluster Alignment (Cross-tabulation):**\n",
    "   * **Cluster 0** shows a stronger concentration of **Actual 0 (Poor Value)**.\n",
    "   * **Cluster 1** seems to be a \"high-value\" cluster, capturing a large portion of **Actual 2 (Excellent Value)**.\n",
    "   * **Cluster 2** remains somewhat mixed but shows a leaning towards Excellent listings.\n",
    "\n",
    "**Conclusion:** While GMM is the most successful unsupervised model so far, the overall low alignment with ground truth labels suggests that the raw feature space is still too noisy or complex for direct clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Airbnb-Project)",
   "language": "python",
   "name": "airbnb_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
