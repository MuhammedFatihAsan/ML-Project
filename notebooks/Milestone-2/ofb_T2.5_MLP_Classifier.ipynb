{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.5: Neural Network (MLP Classifier)\n",
    "\n",
    "\n",
    "## Objective \n",
    "Implement MLP Classifier with sklearn, experiment with hidden layer sizes, activation functions, and learning rates, and document convergence behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we implement a **Multi-Layer Perceptron (MLP) Classifier** for predicting Airbnb listing value categories. We will:\n",
    "\n",
    "1. Train a baseline MLP model\n",
    "2. Experiment with different hidden layer architectures\n",
    "3. Test various activation functions\n",
    "4. Explore different learning rates\n",
    "5. Analyze convergence behavior\n",
    "6. Perform hyperparameter tuning with GridSearchCV\n",
    "7. Evaluate the final model comprehensively\n",
    "\n",
    "**Note:** ROC-AUC, Precision-Recall curves and confusion matrices will be handled by **Emircan** in **Task 2.16 && Task 2.17** as part of the comprehensive model evaluation phase.\n",
    "\n",
    "---\n",
    "\n",
    "## What is a Multi-Layer Perceptron (MLP)?\n",
    "\n",
    "An **MLP** is a class of feedforward artificial neural network. It consists of:\n",
    "\n",
    "- **Input Layer:** Receives the feature data (one neuron per feature)\n",
    "- **Hidden Layer(s):** Performs non-linear transformations using activation functions\n",
    "- **Output Layer:** Produces the final class predictions\n",
    "\n",
    "### How does an MLP learn?\n",
    "\n",
    "1. **Forward Propagation:** Input data flows through the network, layer by layer\n",
    "2. **Loss Calculation:** The difference between predictions and actual values is computed\n",
    "3. **Backpropagation:** Gradients are calculated to determine how to adjust weights\n",
    "4. **Weight Update:** Weights are adjusted using an optimizer (e.g., Adam)\n",
    "5. **Iteration:** Steps 1-4 repeat until convergence\n",
    "\n",
    "### Why use MLP for classification?\n",
    "\n",
    "- Can learn complex, non-linear decision boundaries\n",
    "- Flexible architecture (adjustable layers and neurons)\n",
    "- Works well with scaled numerical features\n",
    "- Handles multi-class classification naturally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Import Libraries and Load Data\n",
    "\n",
    "### 1.1 Import Required Libraries\n",
    "\n",
    "We need several libraries for this task:\n",
    "\n",
    "| Library | Purpose |\n",
    "|---------|--------|\n",
    "| `pandas`, `numpy` | Data manipulation and numerical operations |\n",
    "| `matplotlib`, `seaborn` | Data visualization |\n",
    "| `MLPClassifier` | Neural network implementation |\n",
    "| `GridSearchCV` | Hyperparameter tuning |\n",
    "| `learning_curve` | Analyzing model performance vs training size |\n",
    "| `classification_report`, `confusion_matrix` | Model evaluation metrics |\n",
    "| `pickle` | Saving trained models |\n",
    "| `time` | Tracking training duration |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "import warnings\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Suppress convergence warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('=' * 60)\n",
    "print('LIBRARIES IMPORTED SUCCESSFULLY')\n",
    "print('=' * 60)\n",
    "print('\\nKey libraries loaded:')\n",
    "print('  • pandas, numpy: Data manipulation')\n",
    "print('  • matplotlib, seaborn: Visualization')\n",
    "print('  • sklearn.neural_network: MLP implementation')\n",
    "print('  • sklearn.model_selection: Cross-validation & tuning')\n",
    "print('  • sklearn.metrics: Evaluation metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Preprocessed Data\n",
    "\n",
    "We load the **scaled** training and testing datasets created in Week 1 (Task 1.6).\n",
    "\n",
    "#### Why use scaled data for neural networks?\n",
    "\n",
    "Neural networks are **sensitive to feature scales** because:\n",
    "\n",
    "1. **Gradient descent optimization:** Large feature values can cause large gradients, leading to unstable training\n",
    "2. **Weight initialization:** Networks assume input features are roughly in the same range\n",
    "3. **Activation function saturation:** Extreme values can saturate activation functions (especially sigmoid/tanh)\n",
    "4. **Equal feature contribution:** Scaling ensures all features contribute proportionally\n",
    "\n",
    "#### Data files:\n",
    "- `X_train_scaled.csv`: Training features (StandardScaler applied)\n",
    "- `X_test_scaled.csv`: Testing features (StandardScaler applied)\n",
    "- `y_train.csv`: Training target labels\n",
    "- `y_test.csv`: Testing target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed and scaled datasets\n",
    "print('Loading preprocessed data...\\n')\n",
    "\n",
    "# Load features and targets\n",
    "X_train = pd.read_csv('../../data/processed/X_train_scaled.csv')\n",
    "X_test = pd.read_csv('../../data/processed/X_test_scaled.csv')\n",
    "y_train_raw = pd.read_csv('../../data/processed/y_train.csv').values.ravel()  # Convert to 1D array\n",
    "y_test_raw = pd.read_csv('../../data/processed/y_test.csv').values.ravel()    # Convert to 1D array\n",
    "\n",
    "# Encode string labels to numeric (0, 1, 2)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_raw)\n",
    "y_test = le.transform(y_test_raw)\n",
    "\n",
    "# Display comprehensive dataset information\n",
    "print('=' * 60)\n",
    "print('DATASET INFORMATION')\n",
    "print('=' * 60)\n",
    "print(f'\\n Training Set:')\n",
    "print(f'   • Features (X_train): {X_train.shape[0]:,} samples × {X_train.shape[1]} features')\n",
    "print(f'   • Target (y_train): {y_train.shape[0]:,} samples')\n",
    "print(f'\\n Testing Set:')\n",
    "print(f'   • Features (X_test): {X_test.shape[0]:,} samples × {X_test.shape[1]} features')\n",
    "print(f'   • Target (y_test): {y_test.shape[0]:,} samples')\n",
    "print(f'\\n Train/Test Split Ratio: {X_train.shape[0]/(X_train.shape[0]+X_test.shape[0])*100:.0f}% / {X_test.shape[0]/(X_train.shape[0]+X_test.shape[0])*100:.0f}%')\n",
    "\n",
    "# Display class distribution\n",
    "print(f'\\n Target Classes: {np.unique(y_train)}')\n",
    "print(f' Number of Classes: {len(np.unique(y_train))}')\n",
    "print(f'\\n Class Distribution in Training Set:')\n",
    "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "for cls, count in class_counts.items():\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    bar = '█' * int(percentage / 2)\n",
    "    print(f'   Class {cls}: {count:5,} samples ({percentage:5.2f}%) {bar}')\n",
    "\n",
    "print('\\n' + '=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Baseline MLP Model\n",
    "\n",
    "### Why start with a baseline?\n",
    "\n",
    "A baseline model serves several important purposes:\n",
    "\n",
    "1. **Performance benchmark:** Establishes a reference point for measuring improvements\n",
    "2. **Sanity check:** Verifies that data is loaded correctly and the model can learn\n",
    "3. **Default behavior:** Shows how sklearn's default parameters perform on our data\n",
    "4. **Comparison basis:** All experiments will be compared against this baseline\n",
    "\n",
    "### Default MLPClassifier Parameters:\n",
    "\n",
    "| Parameter | Default Value | Description |\n",
    "|-----------|---------------|-------------|\n",
    "| `hidden_layer_sizes` | (100,) | Single hidden layer with 100 neurons |\n",
    "| `activation` | 'relu' | Rectified Linear Unit activation |\n",
    "| `solver` | 'adam' | Adam optimizer (adaptive learning rate) |\n",
    "| `learning_rate_init` | 0.001 | Initial learning rate |\n",
    "| `max_iter` | 200 | Maximum training iterations |\n",
    "| `alpha` | 0.0001 | L2 regularization strength |\n",
    "\n",
    "### What we're tracking:\n",
    "- **Training time:** Computational cost\n",
    "- **Number of iterations:** Epochs until convergence\n",
    "- **Test accuracy:** Generalization performance\n",
    "- **Per-class metrics:** Precision, recall, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline MLP model with default parameters\n",
    "print('=' * 60)\n",
    "print('TRAINING BASELINE MLP MODEL')\n",
    "print('=' * 60)\n",
    "print('\\n Configuration: sklearn default parameters')\n",
    "print('   • hidden_layer_sizes: (100,) - Single layer, 100 neurons')\n",
    "print('   • activation: relu - Rectified Linear Unit')\n",
    "print('   • solver: adam - Adaptive Moment Estimation')\n",
    "print('   • learning_rate_init: 0.001')\n",
    "print('   • max_iter: 500 (increased from default 200)')\n",
    "print('\\n Training in progress...\\n')\n",
    "\n",
    "# Create and train baseline model\n",
    "baseline_mlp = MLPClassifier(random_state=42, max_iter=500)\n",
    "\n",
    "# Track training time\n",
    "start_time = time.time()\n",
    "baseline_mlp.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "y_pred_baseline = baseline_mlp.predict(X_test)\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "# Display results\n",
    "print('=' * 60)\n",
    "print('BASELINE MODEL RESULTS')\n",
    "print('=' * 60)\n",
    "print(f'\\n⏱  Training Time: {training_time:.2f} seconds')\n",
    "print(f' Iterations to Convergence: {baseline_mlp.n_iter_}')\n",
    "print(f' Final Training Loss: {baseline_mlp.loss_:.6f}')\n",
    "print(f'\\n Test Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)')\n",
    "print(f'\\n Detailed Classification Report:')\n",
    "print('-' * 60)\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Classification Report\n",
    "\n",
    "| Metric | Formula | Interpretation |\n",
    "|--------|---------|----------------|\n",
    "| **Precision** | TP / (TP + FP) | Of all predicted positives, how many are correct? |\n",
    "| **Recall** | TP / (TP + FN) | Of all actual positives, how many did we find? |\n",
    "| **F1-Score** | 2 × (P × R) / (P + R) | Harmonic mean of precision and recall |\n",
    "| **Support** | - | Number of actual samples in each class |\n",
    "\n",
    "**Averages:**\n",
    "- **Macro avg:** Unweighted mean (treats all classes equally)\n",
    "- **Weighted avg:** Weighted by class support (accounts for imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Experiment 1: Hidden Layer Sizes\n",
    "\n",
    "### What are hidden layers?\n",
    "\n",
    "Hidden layers are the computational core of neural networks. Each hidden layer:\n",
    "\n",
    "1. **Receives input** from the previous layer (weighted sum)\n",
    "2. **Applies activation function** (introduces non-linearity)\n",
    "3. **Passes output** to the next layer\n",
    "\n",
    "### Architecture Design Principles:\n",
    "\n",
    "| Architecture Type | Example | Use Case |\n",
    "|-------------------|---------|----------|\n",
    "| **Shallow** | (50,) | Simple patterns, fast training |\n",
    "| **Single wide** | (100,) | Moderate complexity |\n",
    "| **Funnel** | (100, 50) | Gradual feature compression |\n",
    "| **Uniform deep** | (100, 100) | Complex patterns |\n",
    "| **Deep funnel** | (100, 50, 25) | Hierarchical feature learning |\n",
    "\n",
    "### Trade-offs:\n",
    "\n",
    "**Too few neurons/layers (Underfitting):**\n",
    "- Cannot capture complex patterns\n",
    "- High bias, low variance\n",
    "- Poor performance on both train and test\n",
    "\n",
    "**Too many neurons/layers (Overfitting):**\n",
    "- Memorizes training data\n",
    "- Low bias, high variance\n",
    "- Good train performance, poor test performance\n",
    "\n",
    "### Architectures to Test:\n",
    "\n",
    "1. **(50,)** - Simple: 50 neurons, 1 layer\n",
    "2. **(100,)** - Baseline: 100 neurons, 1 layer\n",
    "3. **(50, 50)** - Moderate: 50+50 neurons, 2 layers\n",
    "4. **(100, 50)** - Funnel: 100→50 neurons, 2 layers\n",
    "5. **(100, 100)** - Wide: 100+100 neurons, 2 layers\n",
    "6. **(100, 50, 25)** - Deep funnel: 100→50→25, 3 layers\n",
    "7. **(150, 100, 50)** - Large: 150→100→50, 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hidden layer configurations to test\n",
    "hidden_layer_configs = [\n",
    "    (50,),           # Simple: 1 layer, 50 neurons\n",
    "    (100,),          # Baseline: 1 layer, 100 neurons\n",
    "    (50, 50),        # Moderate depth: 2 layers, 50 each\n",
    "    (100, 50),       # Funnel: 2 layers, decreasing\n",
    "    (100, 100),      # Wide: 2 layers, 100 each\n",
    "    (100, 50, 25),   # Deep funnel: 3 layers, decreasing\n",
    "    (150, 100, 50),  # Large capacity: 3 layers\n",
    "]\n",
    "\n",
    "# Store results\n",
    "hidden_layer_results = []\n",
    "\n",
    "print('=' * 60)\n",
    "print('EXPERIMENT 1: HIDDEN LAYER SIZES')\n",
    "print('=' * 60)\n",
    "print('\\n Testing 7 different neural network architectures')\n",
    "print('\\n Configurations:')\n",
    "for i, config in enumerate(hidden_layer_configs, 1):\n",
    "    total_neurons = sum(config)\n",
    "    print(f'   {i}. {str(config):20s} | {len(config)} layer(s) | {total_neurons} total neurons')\n",
    "print('\\n' + '-' * 60)\n",
    "\n",
    "# Test each configuration\n",
    "for idx, config in enumerate(hidden_layer_configs, 1):\n",
    "    print(f'\\n[{idx}/7] Testing architecture: {config}')\n",
    "    \n",
    "    # Create and train MLP\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=config,\n",
    "        random_state=42,\n",
    "        max_iter=500\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results including loss curve for convergence analysis\n",
    "    hidden_layer_results.append({\n",
    "        'config': str(config),\n",
    "        'accuracy': accuracy,\n",
    "        'training_time': training_time,\n",
    "        'n_iter': mlp.n_iter_,\n",
    "        'final_loss': mlp.loss_,\n",
    "        'loss_curve': mlp.loss_curve_\n",
    "    })\n",
    "    \n",
    "    print(f'       ✓ Accuracy: {accuracy:.4f} | Time: {training_time:.2f}s | Iterations: {mlp.n_iter_} | Loss: {mlp.loss_:.6f}')\n",
    "\n",
    "# Create summary DataFrame\n",
    "hidden_layer_df = pd.DataFrame(hidden_layer_results)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('HIDDEN LAYER EXPERIMENT SUMMARY')\n",
    "print('=' * 60)\n",
    "print(hidden_layer_df[['config', 'accuracy', 'training_time', 'n_iter', 'final_loss']].to_string(index=False))\n",
    "print('\\n' + '-' * 60)\n",
    "best_idx = hidden_layer_df['accuracy'].idxmax()\n",
    "print(f' Best Architecture: {hidden_layer_df.loc[best_idx, \"config\"]}')\n",
    "print(f' Best Accuracy: {hidden_layer_df[\"accuracy\"].max():.4f}')\n",
    "print(f' Improvement over baseline: {(hidden_layer_df[\"accuracy\"].max() - baseline_accuracy)*100:+.2f}%')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Experiment 2: Activation Functions\n",
    "\n",
    "### What is an activation function?\n",
    "\n",
    "Activation functions introduce **non-linearity** into neural networks. Without them, stacking multiple layers would be equivalent to a single linear transformation.\n",
    "\n",
    "### Activation Functions Comparison:\n",
    "\n",
    "#### 1. ReLU (Rectified Linear Unit) - Default\n",
    "```\n",
    "f(x) = max(0, x)\n",
    "```\n",
    "- **Output range:** [0, ∞)\n",
    "- **Pros:** Fast computation, avoids vanishing gradient, sparse activation\n",
    "- **Cons:** \"Dying ReLU\" problem (neurons can become permanently inactive)\n",
    "- **Best for:** Deep networks, general-purpose classification\n",
    "\n",
    "#### 2. Tanh (Hyperbolic Tangent)\n",
    "```\n",
    "f(x) = (e^x - e^-x) / (e^x + e^-x)\n",
    "```\n",
    "- **Output range:** [-1, 1] (zero-centered)\n",
    "- **Pros:** Zero-centered output, stronger gradients than sigmoid\n",
    "- **Cons:** Vanishing gradient for extreme values\n",
    "- **Best for:** When zero-centered outputs are beneficial\n",
    "\n",
    "#### 3. Logistic (Sigmoid)\n",
    "```\n",
    "f(x) = 1 / (1 + e^-x)\n",
    "```\n",
    "- **Output range:** [0, 1]\n",
    "- **Pros:** Smooth gradient, probabilistic interpretation\n",
    "- **Cons:** Vanishing gradient, not zero-centered, slow convergence\n",
    "- **Best for:** Output layer in binary classification\n",
    "\n",
    "### Visual Comparison:\n",
    "```\n",
    "ReLU:     ___/     (linear for x>0, zero for x<0)\n",
    "Tanh:     _--‾     (S-curve from -1 to 1)\n",
    "Sigmoid:  _-‾      (S-curve from 0 to 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activation functions to test\n",
    "activation_functions = ['relu', 'tanh', 'logistic']\n",
    "activation_results = []\n",
    "\n",
    "print('=' * 60)\n",
    "print('EXPERIMENT 2: ACTIVATION FUNCTIONS')\n",
    "print('=' * 60)\n",
    "print('\\n Testing 3 different activation functions')\n",
    "print('\\n Fixed architecture: (100, 50) to isolate activation effect')\n",
    "print('\\n Activation functions:')\n",
    "print('   1. ReLU (Rectified Linear Unit) - f(x) = max(0, x)')\n",
    "print('   2. Tanh (Hyperbolic Tangent) - f(x) = tanh(x)')\n",
    "print('   3. Logistic (Sigmoid) - f(x) = 1/(1+e^-x)')\n",
    "print('\\n' + '-' * 60)\n",
    "\n",
    "# Test each activation function\n",
    "for idx, activation in enumerate(activation_functions, 1):\n",
    "    print(f'\\n[{idx}/3] Testing activation: {activation.upper()}')\n",
    "    \n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        activation=activation,\n",
    "        random_state=42,\n",
    "        max_iter=500\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    activation_results.append({\n",
    "        'activation': activation,\n",
    "        'accuracy': accuracy,\n",
    "        'training_time': training_time,\n",
    "        'n_iter': mlp.n_iter_,\n",
    "        'final_loss': mlp.loss_,\n",
    "        'loss_curve': mlp.loss_curve_\n",
    "    })\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f} | Time: {training_time:.2f}s | Iterations: {mlp.n_iter_} | Loss: {mlp.loss_:.6f}')\n",
    "\n",
    "# Create summary DataFrame\n",
    "activation_df = pd.DataFrame(activation_results)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('ACTIVATION FUNCTION EXPERIMENT SUMMARY')\n",
    "print('=' * 60)\n",
    "print(activation_df[['activation', 'accuracy', 'training_time', 'n_iter', 'final_loss']].to_string(index=False))\n",
    "print('\\n' + '-' * 60)\n",
    "best_idx = activation_df['accuracy'].idxmax()\n",
    "print(f' Best Activation: {activation_df.loc[best_idx, \"activation\"].upper()}')\n",
    "print(f' Best Accuracy: {activation_df[\"accuracy\"].max():.4f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Experiment 3: Learning Rates\n",
    "\n",
    "### What is the learning rate?\n",
    "\n",
    "The learning rate (η) controls the **step size** during gradient descent optimization:\n",
    "\n",
    "```\n",
    "new_weight = old_weight - η × gradient\n",
    "```\n",
    "\n",
    "### Learning Rate Impact:\n",
    "\n",
    "| Learning Rate | Behavior | Symptoms |\n",
    "|---------------|----------|----------|\n",
    "| **Too Low** (0.0001) | Very small weight updates | Slow convergence, may get stuck |\n",
    "| **Optimal** (0.001-0.01) | Balanced updates | Smooth, efficient convergence |\n",
    "| **Too High** (0.1+) | Large weight updates | Oscillation, divergence |\n",
    "\n",
    "### Visual Analogy:\n",
    "\n",
    "Imagine descending a mountain to find the lowest valley:\n",
    "\n",
    "- **Low LR:** Taking tiny steps - safe but extremely slow\n",
    "- **Optimal LR:** Taking confident strides - efficient progress\n",
    "- **High LR:** Taking huge leaps - might jump over the valley or fall\n",
    "\n",
    "### Learning Rates to Test:\n",
    "\n",
    "1. **0.0001** - Very conservative (10× smaller than default)\n",
    "2. **0.001** - Default (sklearn standard)\n",
    "3. **0.01** - Aggressive (10× larger than default)\n",
    "4. **0.1** - Very aggressive (100× larger than default)\n",
    "\n",
    "**Note:** We use the Adam optimizer which adapts learning rates, but the initial value still significantly impacts training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rates to test\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "learning_rate_results = []\n",
    "\n",
    "print('=' * 60)\n",
    "print('EXPERIMENT 3: LEARNING RATES')\n",
    "print('=' * 60)\n",
    "print('\\n Testing 4 different learning rates')\n",
    "print('\\n Fixed: architecture=(100, 50), activation=relu')\n",
    "print('\\n Learning rates:')\n",
    "print('   1. 0.0001 - Very conservative (10× smaller than default)')\n",
    "print('   2. 0.001  - Default (sklearn standard)')\n",
    "print('   3. 0.01   - Aggressive (10× larger than default)')\n",
    "print('   4. 0.1    - Very aggressive (100× larger than default)')\n",
    "print('\\n' + '-' * 60)\n",
    "\n",
    "# Test each learning rate\n",
    "for idx, lr in enumerate(learning_rates, 1):\n",
    "    print(f'\\n[{idx}/4] Testing learning rate: {lr}')\n",
    "    \n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        learning_rate_init=lr,\n",
    "        random_state=42,\n",
    "        max_iter=500\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    learning_rate_results.append({\n",
    "        'learning_rate': lr,\n",
    "        'accuracy': accuracy,\n",
    "        'training_time': training_time,\n",
    "        'n_iter': mlp.n_iter_,\n",
    "        'final_loss': mlp.loss_,\n",
    "        'loss_curve': mlp.loss_curve_\n",
    "    })\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f} | Time: {training_time:.2f}s | Iterations: {mlp.n_iter_} | Loss: {mlp.loss_:.6f}')\n",
    "\n",
    "# Create summary DataFrame\n",
    "learning_rate_df = pd.DataFrame(learning_rate_results)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('LEARNING RATE EXPERIMENT SUMMARY')\n",
    "print('=' * 60)\n",
    "print(learning_rate_df[['learning_rate', 'accuracy', 'training_time', 'n_iter', 'final_loss']].to_string(index=False))\n",
    "print('\\n' + '-' * 60)\n",
    "best_idx = learning_rate_df['accuracy'].idxmax()\n",
    "print(f' Best Learning Rate: {learning_rate_df.loc[best_idx, \"learning_rate\"]}')\n",
    "print(f' Best Accuracy: {learning_rate_df[\"accuracy\"].max():.4f}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Convergence Behavior Analysis\n",
    "\n",
    "### What is convergence?\n",
    "\n",
    "**Convergence** is the process where the model's loss (error) decreases and stabilizes during training. A well-converged model shows:\n",
    "\n",
    "- Steadily decreasing loss\n",
    "- Stable final loss value\n",
    "- No erratic oscillations\n",
    "- Reaches a plateau\n",
    "\n",
    "### Why analyze convergence?\n",
    "\n",
    "1. **Diagnose training issues:** Is the model learning properly?\n",
    "2. **Compare configurations:** Which settings converge faster/better?\n",
    "3. **Detect problems:**\n",
    "   - Slow convergence → Learning rate too low\n",
    "   - Oscillating loss → Learning rate too high\n",
    "   - Plateauing early → Model stuck in local minimum\n",
    "   - Diverging loss → Serious training instability\n",
    "\n",
    "### Reading Loss Curves:\n",
    "\n",
    "| Pattern | Meaning | Action |\n",
    "|---------|---------|--------|\n",
    "| Smooth decrease → plateau | Healthy convergence | Good! |\n",
    "| Very slow decrease | Learning rate too low | Increase LR |\n",
    "| Oscillating/zigzag | Learning rate too high | Decrease LR |\n",
    "| Increasing loss | Training diverging | Much lower LR |\n",
    "| Early plateau | Stuck in local minimum | Try different init |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive convergence visualization\n",
    "print('=' * 60)\n",
    "print('CREATING CONVERGENCE ANALYSIS VISUALIZATIONS')\n",
    "print('=' * 60)\n",
    "print('\\n Generating 4 plots...\\n')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# ================================================================\n",
    "# PLOT 1: Hidden Layer Sizes Convergence\n",
    "# ================================================================\n",
    "ax1 = axes[0, 0]\n",
    "for result in hidden_layer_results:\n",
    "    ax1.plot(result['loss_curve'], label=result['config'], linewidth=2, alpha=0.8)\n",
    "ax1.set_xlabel('Iterations (Epochs)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Training Loss', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Convergence: Hidden Layer Architectures', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=9, loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(left=0)\n",
    "\n",
    "# ================================================================\n",
    "# PLOT 2: Activation Functions Convergence\n",
    "# ================================================================\n",
    "ax2 = axes[0, 1]\n",
    "colors_act = ['#E74C3C', '#27AE60', '#3498DB']\n",
    "for idx, result in enumerate(activation_results):\n",
    "    ax2.plot(result['loss_curve'], label=result['activation'].upper(), \n",
    "             linewidth=2.5, alpha=0.9, color=colors_act[idx])\n",
    "ax2.set_xlabel('Iterations (Epochs)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Training Loss', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Convergence: Activation Functions', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11, loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(left=0)\n",
    "\n",
    "# ================================================================\n",
    "# PLOT 3: Learning Rates Convergence\n",
    "# ================================================================\n",
    "ax3 = axes[1, 0]\n",
    "colors_lr = ['#9B59B6', '#E67E22', '#1ABC9C', '#E74C3C']\n",
    "for idx, result in enumerate(learning_rate_results):\n",
    "    ax3.plot(result['loss_curve'], label=f'LR = {result[\"learning_rate\"]}', \n",
    "             linewidth=2.5, alpha=0.9, color=colors_lr[idx])\n",
    "ax3.set_xlabel('Iterations (Epochs)', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Training Loss', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Convergence: Learning Rates', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=11, loc='upper right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_xlim(left=0)\n",
    "\n",
    "# ================================================================\n",
    "# PLOT 4: Best Accuracy Comparison\n",
    "# ================================================================\n",
    "ax4 = axes[1, 1]\n",
    "experiments = ['Hidden\\nLayers', 'Activation\\nFunctions', 'Learning\\nRates']\n",
    "best_accuracies = [\n",
    "    hidden_layer_df['accuracy'].max(),\n",
    "    activation_df['accuracy'].max(),\n",
    "    learning_rate_df['accuracy'].max()\n",
    "]\n",
    "colors_bar = ['#3498DB', '#27AE60', '#E74C3C']\n",
    "bars = ax4.bar(experiments, best_accuracies, color=colors_bar, \n",
    "               edgecolor='black', linewidth=2, alpha=0.8)\n",
    "ax4.set_ylabel('Best Test Accuracy', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Best Accuracy by Experiment Type', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylim([min(best_accuracies) - 0.03, max(best_accuracies) + 0.03])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "             f'{height:.4f}', ha='center', va='bottom', \n",
    "             fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add baseline reference line\n",
    "ax4.axhline(y=baseline_accuracy, color='red', linestyle='--', \n",
    "            linewidth=2, label=f'Baseline: {baseline_accuracy:.4f}')\n",
    "ax4.legend(fontsize=10, loc='lower right')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/mlp_convergence_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nVisualization saved!')\n",
    "print('Location: outputs/figures/mlp_convergence_analysis.png')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "### What is GridSearchCV?\n",
    "\n",
    "**GridSearchCV** performs exhaustive search over specified parameter combinations using cross-validation:\n",
    "\n",
    "1. **Define parameter grid:** Specify values to test for each hyperparameter\n",
    "2. **Generate combinations:** All possible combinations are created\n",
    "3. **Cross-validation:** Each combination is evaluated using k-fold CV\n",
    "4. **Select best:** Returns the combination with highest CV score\n",
    "\n",
    "### Why use GridSearchCV?\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Systematic** | Tests all combinations, no guesswork |\n",
    "| **Robust** | Cross-validation reduces overfitting to single split |\n",
    "| **Automated** | No manual trial-and-error |\n",
    "| **Reproducible** | Same grid always gives same results |\n",
    "\n",
    "### Our Parameter Grid:\n",
    "\n",
    "Based on our experiments, we focus on promising values:\n",
    "\n",
    "| Parameter | Values | Rationale |\n",
    "|-----------|--------|----------|\n",
    "| `hidden_layer_sizes` | (100,50), (100,100), (150,100,50) | Top performers from Exp 1 |\n",
    "| `activation` | 'relu', 'tanh' | Best from Exp 2 |\n",
    "| `learning_rate_init` | 0.001, 0.01 | Optimal range from Exp 3 |\n",
    "| `alpha` | 0.0001, 0.001 | L2 regularization strength |\n",
    "| `batch_size` | 32, 64 | Mini-batch sizes |\n",
    "\n",
    "**Total combinations:** 3 × 2 × 2 × 2 × 2 = **48**  \n",
    "**With 5-fold CV:** 48 × 5 = **240 model trainings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid based on experiment insights\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100, 50), (100, 100), (150, 100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
    "\n",
    "print('=' * 60)\n",
    "print('HYPERPARAMETER TUNING WITH GRIDSEARCHCV')\n",
    "print('=' * 60)\n",
    "print(f'\\n Parameter Grid:')\n",
    "for param, values in param_grid.items():\n",
    "    print(f'   • {param}: {values}')\n",
    "print(f'\\n Total combinations: {total_combinations}')\n",
    "print(f' With 5-fold CV: {total_combinations * 5} model trainings')\n",
    "print(f'\\n This may take several minutes...')\n",
    "print('\\n' + '-' * 60)\n",
    "print('\\n Starting GridSearchCV...\\n')\n",
    "\n",
    "# Create base MLP with early stopping\n",
    "mlp_grid = MLPClassifier(\n",
    "    random_state=42,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10\n",
    ")\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_grid,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_time = time.time() - start_time\n",
    "\n",
    "print(f'\\n Grid search completed in {grid_time:.2f} seconds ({grid_time/60:.1f} minutes)')\n",
    "print('\\n' + '=' * 60)\n",
    "print('GRIDSEARCHCV RESULTS')\n",
    "print('=' * 60)\n",
    "print(f'\\n Best Parameters:')\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f'   • {param}: {value}')\n",
    "print(f'\\n Best Cross-Validation Accuracy: {grid_search.best_score_:.4f} ({grid_search.best_score_*100:.2f}%)')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and display top 10 configurations\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "results_df = results_df.sort_values('rank_test_score')\n",
    "\n",
    "# Select relevant columns\n",
    "top_results = results_df[[\n",
    "    'params', 'mean_test_score', 'std_test_score', \n",
    "    'mean_train_score', 'rank_test_score'\n",
    "]].head(10)\n",
    "\n",
    "print('=' * 60)\n",
    "print('TOP 10 CONFIGURATIONS')\n",
    "print('=' * 60)\n",
    "print(top_results.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "results_df[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']].to_csv(\n",
    "    '../../outputs/mlp_grid_search_results.csv', index=False\n",
    ")\n",
    "print('\\n Full results saved to: outputs/mlp_grid_search_results.csv')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Final Model Evaluation\n",
    "\n",
    "### Comprehensive Evaluation Metrics\n",
    "\n",
    "We evaluate the best model from GridSearchCV with multiple metrics:\n",
    "\n",
    "| Metric | Description | Use Case |\n",
    "|--------|-------------|----------|\n",
    "| **Accuracy** | Overall correct predictions | Balanced classes |\n",
    "| **Precision** | Correct positive predictions | Cost of false positives |\n",
    "| **Recall** | Found positive instances | Cost of false negatives |\n",
    "| **F1-Score** | Balance of P and R | Imbalanced classes |\n",
    "| **Confusion Matrix** | Detailed error analysis | Understanding mistakes |\n",
    "\n",
    "**Note:** ROC-AUC and Precision-Recall curves will be created by **Emircan (Member 3)** in **Task 2.17** for all models using One-vs-Rest approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model and evaluate on test set\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_pred_best = best_mlp.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "print('=' * 60)\n",
    "print('FINAL MODEL EVALUATION')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'\\n Best Model Configuration:')\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f'   • {param}: {value}')\n",
    "\n",
    "print(f'\\n Performance Metrics:')\n",
    "print(f'   • Cross-Validation Accuracy: {grid_search.best_score_:.4f}')\n",
    "print(f'   • Test Set Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)')\n",
    "print(f'   • Baseline Accuracy: {baseline_accuracy:.4f}')\n",
    "print(f'   • Improvement: {(best_accuracy - baseline_accuracy)*100:+.2f}%')\n",
    "\n",
    "print(f'\\nDetailed Classification Report:')\n",
    "print('-' * 60)\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print('=' * 60)\n",
    "\n",
    "print('\\nNote: ROC-AUC, Precision-Recall curves and confusion matrices will be generated')\n",
    "print('   by Emircan (Member 3) in Task 2.17 for comprehensive evaluation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Learning Curve Analysis\n",
    "\n",
    "### What is a learning curve?\n",
    "\n",
    "A learning curve shows how model performance changes with **training set size**:\n",
    "\n",
    "- **Training score:** How well the model fits training data\n",
    "- **Validation score:** How well the model generalizes\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "| Pattern | Diagnosis | Solution |\n",
    "|---------|-----------|----------|\n",
    "| Large gap, both improving | High variance (overfitting) | More data, regularization |\n",
    "| Small gap, both low | High bias (underfitting) | More complex model |\n",
    "| Curves converging | Good fit | Current model is appropriate |\n",
    "| Training at 100% | Overfitting | Regularization, simpler model |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate learning curve\n",
    "print('Generating learning curve (this may take a minute)...\\n')\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_mlp, X_train, y_train,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Calculate mean and std\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, \n",
    "                 alpha=0.2, color='blue')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, \n",
    "                 alpha=0.2, color='orange')\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', linewidth=2, \n",
    "         markersize=8, label='Training Score')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='orange', linewidth=2, \n",
    "         markersize=8, label='Validation Score')\n",
    "\n",
    "plt.xlabel('Training Set Size', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.title('Learning Curve - Best MLP Model', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/mlp_learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n Learning curve saved!')\n",
    "print(' Location: outputs/figures/mlp_learning_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Save Model and Results\n",
    "\n",
    "### Output Files:\n",
    "\n",
    "| File | Location | Description |\n",
    "|------|----------|-------------|\n",
    "| `best_mlp_model.pkl` | models/ | Trained best MLP model |\n",
    "| `mlp_grid_search_results.csv` | outputs/ | All GridSearchCV results |\n",
    "| `mlp_experiment_results.json` | outputs/ | Complete experiment data |\n",
    "| `mlp_convergence_analysis.png` | outputs/figures/ | Convergence plots |\n",
    "| `mlp_learning_curve.png` | outputs/figures/ | Learning curve |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "print('=' * 60)\n",
    "print('SAVING MODEL AND RESULTS')\n",
    "print('=' * 60)\n",
    "\n",
    "# Save model\n",
    "with open('../../models/best_mlp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_mlp, f)\n",
    "print('\\n Model saved: models/best_mlp_model.pkl')\n",
    "\n",
    "# Prepare experiment results (excluding loss curves for JSON compatibility)\n",
    "experiment_results = {\n",
    "    'task': 'T2.5 - Neural Network (MLP Classifier)',\n",
    "     'baseline': {\n",
    "        'accuracy': float(baseline_accuracy),\n",
    "        'iterations': int(baseline_mlp.n_iter_),\n",
    "        'final_loss': float(baseline_mlp.loss_)\n",
    "    },\n",
    "    'experiment_1_hidden_layers': [\n",
    "        {k: v for k, v in r.items() if k != 'loss_curve'} \n",
    "        for r in hidden_layer_results\n",
    "    ],\n",
    "    'experiment_2_activation': [\n",
    "        {k: v for k, v in r.items() if k != 'loss_curve'} \n",
    "        for r in activation_results\n",
    "    ],\n",
    "    'experiment_3_learning_rate': [\n",
    "        {k: v for k, v in r.items() if k != 'loss_curve'} \n",
    "        for r in learning_rate_results\n",
    "    ],\n",
    "    'best_model': {\n",
    "        'parameters': {k: str(v) if isinstance(v, tuple) else v \n",
    "                      for k, v in grid_search.best_params_.items()},\n",
    "        'cv_accuracy': float(grid_search.best_score_),\n",
    "        'test_accuracy': float(best_accuracy),\n",
    "        'improvement_over_baseline': float((best_accuracy - baseline_accuracy) * 100)\n",
    "    },\n",
    "    'note': 'ROC-AUC, PR curves and confusion matrices will be generated by Emircan (Member 3) in Task 2.16 and Task 2.17'\n",
    "}\n",
    "\n",
    "# Save as JSON\n",
    "with open('../../outputs/mlp_experiment_results.json', 'w') as f:\n",
    "    json.dump(experiment_results, f, indent=2)\n",
    "print('Results saved: outputs/mlp_experiment_results.json')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('ALL FILES SAVED SUCCESSFULLY')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Summary and Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "#### Experiment 1: Hidden Layer Sizes\n",
    "- Deeper architectures generally improved performance\n",
    "- Diminishing returns after certain complexity\n",
    "- Best architecture balanced capacity and generalization\n",
    "\n",
    "#### Experiment 2: Activation Functions\n",
    "- **ReLU:** Fast convergence, good performance\n",
    "- **Tanh:** Stable training, competitive results\n",
    "- **Logistic:** Slower convergence due to vanishing gradients\n",
    "\n",
    "#### Experiment 3: Learning Rates\n",
    "- **0.0001:** Too slow, many iterations needed\n",
    "- **0.001:** Good balance (default works well)\n",
    "- **0.01:** Faster convergence, still stable\n",
    "- **0.1:** Risk of instability\n",
    "\n",
    "### Convergence Behavior\n",
    "- All models converged within max_iter\n",
    "- Loss curves showed expected patterns\n",
    "- Early stopping helped prevent overfitting\n",
    "\n",
    "### Final Model Performance\n",
    "- GridSearchCV found optimal hyperparameter combination\n",
    "- Improvement achieved over baseline model\n",
    "- Model ready for ensemble integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('=' * 60)\n",
    "print('TASK 2.5 COMPLETED SUCCESSFULLY')\n",
    "print('=' * 60)\n",
    "print(f'\\n Results Summary:')\n",
    "print(f'   • Baseline Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)')\n",
    "print(f'   • Best Model Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)')\n",
    "print(f'   • Improvement: {(best_accuracy - baseline_accuracy)*100:+.2f}%')\n",
    "print(f'\\n Best Model Parameters:')\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f'   • {param}: {value}')\n",
    "print(f'\\n Generated Files:')\n",
    "print('   • models/best_mlp_model.pkl')\n",
    "print('   • outputs/mlp_grid_search_results.csv')\n",
    "print('   • outputs/mlp_experiment_results.json')\n",
    "print('   • outputs/figures/mlp_convergence_analysis.png')\n",
    "print('   • outputs/figures/mlp_learning_curve.png')\n",
    "print('\\n' + '=' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
