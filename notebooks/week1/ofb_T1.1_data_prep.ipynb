{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Task 1.1: Initial Data Exploration\n",
    "\n",
    "Before diving into modeling, we must first understand the landscape of our data—and that's exactly what this task accomplished. We explored two Airbnb datasets from San Francisco (7,780 listings) and San Diego (13,162 listings), confirming their structural compatibility with identical column schemas across 79 features. A thorough missing values audit revealed that while most columns are complete, review scores carry 30-40% missing data—a pattern we'll address in preprocessing. We identified key data quality issues: prices stored as strings with currency symbols, high-cardinality categorical variables like `neighbourhood` and `property_type`, and several columns with over 50% missing values destined for removal. This exploratory groundwork provides the roadmap for all subsequent cleaning and feature engineering decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load both datasets\n",
    "sf_df = pd.read_csv('../../data/raw/san francisco.csv')\n",
    "sd_df = pd.read_csv('../../data/raw/san diego.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"T1.1: INITIAL DATA EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n San Francisco Dataset:\")\n",
    "print(f\"   - Rows: {sf_df.shape[0]:,}\")\n",
    "print(f\"   - Columns: {sf_df.shape[1]}\")\n",
    "\n",
    "print(f\"\\n San Diego Dataset:\")\n",
    "print(f\"   - Rows: {sd_df.shape[0]:,}\")\n",
    "print(f\"   - Columns: {sd_df.shape[1]}\")\n",
    "\n",
    "print(f\"\\n Combined Dataset (if merged):\")\n",
    "print(f\"   - Total Rows: {sf_df.shape[0] + sd_df.shape[0]:,}\")\n",
    "\n",
    "# Check if columns match\n",
    "sf_cols = set(sf_df.columns)\n",
    "sd_cols = set(sd_df.columns)\n",
    "print(f\"\\n✓ Column names match: {sf_cols == sd_cols}\")\n",
    "\n",
    "if sf_cols != sd_cols:\n",
    "    print(f\"   - Columns only in SF: {sf_cols - sd_cols}\")\n",
    "    print(f\"   - Columns only in SD: {sd_cols - sf_cols}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. COLUMN STRUCTURE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal Columns: {sf_df.shape[1]}\")\n",
    "print(\"\\nColumn Names:\")\n",
    "for i, col in enumerate(sf_df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. DATA TYPES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze data types\n",
    "sf_dtypes = sf_df.dtypes.value_counts()\n",
    "print(\"\\n San Francisco Data Types:\")\n",
    "for dtype, count in sf_dtypes.items():\n",
    "    print(f\"   - {dtype}: {count} columns\")\n",
    "\n",
    "sd_dtypes = sd_df.dtypes.value_counts()\n",
    "print(\"\\n San Diego Data Types:\")\n",
    "for dtype, count in sd_dtypes.items():\n",
    "    print(f\"   - {dtype}: {count} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. MISSING VALUES ANALYSIS - SAN FRANCISCO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sf_missing = sf_df.isnull().sum()\n",
    "sf_missing_pct = (sf_missing / len(sf_df) * 100).round(2)\n",
    "sf_missing_df = pd.DataFrame({\n",
    "    'Column': sf_missing.index,\n",
    "    'Missing_Count': sf_missing.values,\n",
    "    'Missing_Percentage': sf_missing_pct.values\n",
    "})\n",
    "sf_missing_df = sf_missing_df[sf_missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(f\"\\nColumns with Missing Values: {len(sf_missing_df)}/{len(sf_df.columns)}\")\n",
    "print(\"\\nTop 20 Columns with Most Missing Values:\")\n",
    "print(sf_missing_df.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. MISSING VALUES ANALYSIS - SAN DIEGO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sd_missing = sd_df.isnull().sum()\n",
    "sd_missing_pct = (sd_missing / len(sd_df) * 100).round(2)\n",
    "sd_missing_df = pd.DataFrame({\n",
    "    'Column': sd_missing.index,\n",
    "    'Missing_Count': sd_missing.values,\n",
    "    'Missing_Percentage': sd_missing_pct.values\n",
    "})\n",
    "sd_missing_df = sd_missing_df[sd_missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(f\"\\nColumns with Missing Values: {len(sd_missing_df)}/{len(sd_df.columns)}\")\n",
    "print(\"\\nTop 20 Columns with Most Missing Values:\")\n",
    "print(sd_missing_df.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. KEY NUMERICAL FEATURES SUMMARY - SAN FRANCISCO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Key numerical columns to analyze\n",
    "key_numerical = ['price', 'accommodates', 'bedrooms', 'beds', 'bathrooms', \n",
    "                 'minimum_nights', 'maximum_nights', 'number_of_reviews',\n",
    "                 'review_scores_rating', 'review_scores_accuracy', \n",
    "                 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                 'review_scores_communication', 'review_scores_location',\n",
    "                 'review_scores_value']\n",
    "\n",
    "# Check which columns exist\n",
    "existing_numerical = [col for col in key_numerical if col in sf_df.columns]\n",
    "\n",
    "print(\"\\n San Francisco - Key Numerical Features:\")\n",
    "sf_summary = sf_df[existing_numerical].describe().T\n",
    "sf_summary['missing'] = sf_df[existing_numerical].isnull().sum()\n",
    "sf_summary['missing_pct'] = (sf_summary['missing'] / len(sf_df) * 100).round(2)\n",
    "print(sf_summary[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'missing', 'missing_pct']].to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"7. KEY NUMERICAL FEATURES SUMMARY - SAN DIEGO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n San Diego - Key Numerical Features:\")\n",
    "sd_summary = sd_df[existing_numerical].describe().T\n",
    "sd_summary['missing'] = sd_df[existing_numerical].isnull().sum()\n",
    "sd_summary['missing_pct'] = (sd_summary['missing'] / len(sd_df) * 100).round(2)\n",
    "print(sd_summary[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'missing', 'missing_pct']].to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. KEY CATEGORICAL FEATURES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "key_categorical = ['property_type', 'room_type', 'neighbourhood_cleansed', \n",
    "                   'host_is_superhost', 'instant_bookable']\n",
    "\n",
    "existing_categorical = [col for col in key_categorical if col in sf_df.columns]\n",
    "\n",
    "print(\"\\n San Francisco - Categorical Features:\")\n",
    "for col in existing_categorical:\n",
    "    unique_count = sf_df[col].nunique()\n",
    "    missing = sf_df[col].isnull().sum()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"   - Unique values: {unique_count}\")\n",
    "    print(f\"   - Missing: {missing} ({missing/len(sf_df)*100:.2f}%)\")\n",
    "    if unique_count <= 10:\n",
    "        print(f\"   - Value counts:\")\n",
    "        print(sf_df[col].value_counts().head(10).to_string())\n",
    "\n",
    "print(\"\\n San Diego - Categorical Features:\")\n",
    "for col in existing_categorical:\n",
    "    unique_count = sd_df[col].nunique()\n",
    "    missing = sd_df[col].isnull().sum()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"   - Unique values: {unique_count}\")\n",
    "    print(f\"   - Missing: {missing} ({missing/len(sd_df)*100:.2f}%)\")\n",
    "    if unique_count <= 10:\n",
    "        print(f\"   - Value counts:\")\n",
    "        print(sd_df[col].value_counts().head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. PRICE ANALYSIS (NEEDS CLEANING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n San Francisco - Price Column:\")\n",
    "print(f\"   - Data type: {sf_df['price'].dtype}\")\n",
    "print(f\"   - Sample values: {sf_df['price'].head(10).tolist()}\")\n",
    "print(f\"   - Missing: {sf_df['price'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n San Diego - Price Column:\")\n",
    "print(f\"   - Data type: {sd_df['price'].dtype}\")\n",
    "print(f\"   - Sample values: {sd_df['price'].head(10).tolist()}\")\n",
    "print(f\"   - Missing: {sd_df['price'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n  Note: Price column is stored as string with '$' and ',' - needs cleaning in T1.2\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10. DATA QUALITY ISSUES IDENTIFIED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "issues = []\n",
    "\n",
    "# Check for duplicates\n",
    "sf_dupes = sf_df.duplicated().sum()\n",
    "sd_dupes = sd_df.duplicated().sum()\n",
    "if sf_dupes > 0 or sd_dupes > 0:\n",
    "    issues.append(f\"Duplicate rows: SF={sf_dupes}, SD={sd_dupes}\")\n",
    "\n",
    "# Check price format\n",
    "if sf_df['price'].dtype == 'object':\n",
    "    issues.append(\"Price column needs cleaning (contains '$' and ',')\")\n",
    "\n",
    "# Check high missing value columns\n",
    "high_missing_sf = sf_missing_df[sf_missing_df['Missing_Percentage'] > 50]\n",
    "high_missing_sd = sd_missing_df[sd_missing_df['Missing_Percentage'] > 50]\n",
    "issues.append(f\"Columns with >50% missing: SF={len(high_missing_sf)}, SD={len(high_missing_sd)}\")\n",
    "\n",
    "# Check for columns with all missing\n",
    "all_missing_sf = sf_missing_df[sf_missing_df['Missing_Percentage'] == 100]\n",
    "all_missing_sd = sd_missing_df[sd_missing_df['Missing_Percentage'] == 100]\n",
    "if len(all_missing_sf) > 0 or len(all_missing_sd) > 0:\n",
    "    issues.append(f\"Columns with 100% missing: SF={len(all_missing_sf)}, SD={len(all_missing_sd)}\")\n",
    "\n",
    "print(\"\\n Issues Found:\")\n",
    "for i, issue in enumerate(issues, 1):\n",
    "    print(f\"{i}. {issue}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"T1.1 SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    " Task T1.1 Completed: Initial Data Exploration\n",
    "\n",
    " Dataset Overview:\n",
    "   - San Francisco: {sf_df.shape[0]:,} rows × {sf_df.shape[1]} columns\n",
    "   - San Diego: {sd_df.shape[0]:,} rows × {sd_df.shape[1]} columns\n",
    "   - Combined: {sf_df.shape[0] + sd_df.shape[0]:,} rows\n",
    "\n",
    " Key Findings:\n",
    "   1. Both datasets have {sf_df.shape[1]} columns with matching structure\n",
    "   2. Price column needs cleaning (stored as string with '$' and ',')\n",
    "   3. {len(sf_missing_df)} columns in SF and {len(sd_missing_df)} columns in SD have missing values\n",
    "   4. Review scores have significant missing values (~30-40%)\n",
    "   5. Text columns (description, host_about) need NLP processing \n",
    "   6. Categorical encoding needed for property_type, room_type, neighbourhood\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
