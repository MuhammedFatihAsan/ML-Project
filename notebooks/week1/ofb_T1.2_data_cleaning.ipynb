{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Data Cleaning and Preprocessing\n",
    "\n",
    "This task transformed raw Airbnb data into a clean, model-ready dataset from a **landlord perspective**—using only features available at listing creation time. \n",
    "We merged San Francisco and San Diego listings, removed URLs, text descriptions, and review-based features (avoiding data leakage), and dropped columns with >50% missing values. \n",
    "Data types were converted (prices, percentages, booleans), and feature engineering created `host_years`, `price_per_person`, `price_per_bedroom`, and `availability_rate`. \n",
    "Missing values were imputed (median for numeric, mode for categorical), and price outliers were removed using IQR. \n",
    "The target variable `value_category` was created using an FP Score that balances landlord-controlled features (accommodates, beds, bathrooms, superhost status, instant bookable) against price—classifying listings into Poor, Fair, and Excellent value tiers without using any review data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"T1.2: DATA CLEANING AND PREPROCESSING (LANDLORD PERSPECTIVE)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "sf_df = pd.read_csv('../../data/raw/san francisco.csv')\n",
    "sd_df = pd.read_csv('../../data/raw/san diego.csv')\n",
    "\n",
    "# Add city identifier\n",
    "sf_df['city'] = 'San Francisco'\n",
    "sd_df['city'] = 'San Diego'\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([sf_df, sd_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\n Combined Dataset Shape: {df.shape}\")\n",
    "print(f\"   - Total Rows: {df.shape[0]:,}\")\n",
    "print(f\"   - Total Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing_Count': missing.values,\n",
    "    'Missing_Percentage': missing_pct.values\n",
    "})\n",
    "\n",
    "# Filter columns with missing values\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(f\"\\n Columns with Missing Values: {len(missing_df)}\")\n",
    "print(\"\\nTop 20 Columns with Most Missing Data:\")\n",
    "print(missing_df.head(20).to_string(index=False))\n",
    "\n",
    "# Visualize missing data\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_missing = missing_df.head(20)\n",
    "plt.barh(top_missing['Column'], top_missing['Missing_Percentage'])\n",
    "plt.xlabel('Missing Percentage (%)')\n",
    "plt.title('Top 20 Columns with Missing Values')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/missing_values_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Visualization saved: outputs/figures/missing_values_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection - Remove Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. FEATURE SELECTION - LANDLORD PERSPECTIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define columns to drop (URLs, IDs, text descriptions, REVIEW-BASED FEATURES)\n",
    "columns_to_drop = [\n",
    "    # URLs and IDs\n",
    "    'listing_url', 'scrape_id', 'picture_url', 'host_url', \n",
    "    'host_thumbnail_url', 'host_picture_url',\n",
    "    \n",
    "    # Text descriptions (too noisy for initial model)\n",
    "    'description', 'neighborhood_overview', 'host_about', 'name',\n",
    "    \n",
    "    # Redundant or highly specific\n",
    "    'source', 'calendar_updated', 'last_scraped', 'calendar_last_scraped',\n",
    "    \n",
    "    # License (mostly missing or not useful)\n",
    "    'license',\n",
    "    \n",
    "    # Neighbourhood group (if empty)\n",
    "    'neighbourhood_group_cleansed',\n",
    "    \n",
    "    # Bathrooms (we'll use bathrooms_text instead)\n",
    "    'bathrooms',\n",
    "    \n",
    "    # Host verifications (complex nested data)\n",
    "    'host_verifications',\n",
    "    \n",
    "    # Amenities (complex nested data - can be processed later)\n",
    "    'amenities',\n",
    "    \n",
    "    # *** CRITICAL: REMOVE ALL REVIEW-BASED FEATURES (DATA LEAKAGE) ***\n",
    "    'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "    'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "    'review_scores_value', 'number_of_reviews', 'number_of_reviews_ltm',\n",
    "    'number_of_reviews_l30d', 'first_review', 'last_review', 'reviews_per_month'\n",
    "]\n",
    "\n",
    "# Drop columns that exist in the dataframe\n",
    "columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"\\n Dropped {len(columns_to_drop)} columns (including ALL review-based features)\")\n",
    "print(f\"   - Original: {df.shape[1]} columns\")\n",
    "print(f\"   - After dropping: {df_cleaned.shape[1]} columns\")\n",
    "print(f\"\\n Remaining columns: {df_cleaned.shape[1]}\")\n",
    "print(f\"\\n Note: All review-based features removed to prevent data leakage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Type Conversions and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. DATA TYPE CONVERSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 4.1 Clean price column (remove $ and commas)\n",
    "if 'price' in df_cleaned.columns:\n",
    "    df_cleaned['price'] = df_cleaned['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "    print(\"\\n✓ Cleaned 'price' column (removed $ and commas)\")\n",
    "\n",
    "# 4.2 Convert percentage columns\n",
    "percentage_cols = ['host_response_rate', 'host_acceptance_rate']\n",
    "for col in percentage_cols:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = df_cleaned[col].str.rstrip('%').astype(float) / 100\n",
    "        print(f\"✓ Converted '{col}' to decimal\")\n",
    "\n",
    "# 4.3 Convert boolean columns\n",
    "boolean_cols = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', \n",
    "                'has_availability', 'instant_bookable']\n",
    "for col in boolean_cols:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = df_cleaned[col].map({'t': 1, 'f': 0})\n",
    "        print(f\"✓ Converted '{col}' to binary (0/1)\")\n",
    "\n",
    "# 4.4 Convert date columns\n",
    "date_cols = ['host_since']\n",
    "for col in date_cols:\n",
    "    if col in df_cleaned.columns:\n",
    "        df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')\n",
    "        print(f\"✓ Converted '{col}' to datetime\")\n",
    "\n",
    "# 4.5 Extract number from bathrooms_text\n",
    "if 'bathrooms_text' in df_cleaned.columns:\n",
    "    df_cleaned['bathrooms_numeric'] = df_cleaned['bathrooms_text'].str.extract('(\\d+\\.?\\d*)').astype(float)\n",
    "    print(\"\\n✓ Extracted numeric bathrooms from 'bathrooms_text'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering (Landlord-Controlled Features Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. FEATURE ENGINEERING (LANDLORD PERSPECTIVE ONLY)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 5.1 Host experience (years as host)\n",
    "if 'host_since' in df_cleaned.columns:\n",
    "    df_cleaned['host_years'] = (pd.Timestamp.now() - df_cleaned['host_since']).dt.days / 365.25\n",
    "    print(\"\\n✓ Created 'host_years' feature\")\n",
    "\n",
    "# 5.2 Price per person\n",
    "if 'price' in df_cleaned.columns and 'accommodates' in df_cleaned.columns:\n",
    "    df_cleaned['price_per_person'] = df_cleaned['price'] / df_cleaned['accommodates']\n",
    "    print(\" Created 'price_per_person' feature\")\n",
    "\n",
    "# 5.3 Availability rate\n",
    "if 'availability_365' in df_cleaned.columns:\n",
    "    df_cleaned['availability_rate'] = df_cleaned['availability_365'] / 365\n",
    "    print(\" Created 'availability_rate' feature\")\n",
    "\n",
    "# 5.4 Price per bedroom\n",
    "if 'price' in df_cleaned.columns and 'bedrooms' in df_cleaned.columns:\n",
    "    df_cleaned['price_per_bedroom'] = df_cleaned['price'] / (df_cleaned['bedrooms'] + 1)  # +1 to avoid division by zero\n",
    "    print(\" Created 'price_per_bedroom' feature\")\n",
    "\n",
    "# 5.5 Price per bathroom\n",
    "if 'price' in df_cleaned.columns and 'bathrooms_numeric' in df_cleaned.columns:\n",
    "    df_cleaned['price_per_bathroom'] = df_cleaned['price'] / (df_cleaned['bathrooms_numeric'] + 0.5)\n",
    "    print(\" Created 'price_per_bathroom' feature\")\n",
    "\n",
    "# 5.6 Space efficiency (beds per accommodation)\n",
    "if 'beds' in df_cleaned.columns and 'accommodates' in df_cleaned.columns:\n",
    "    df_cleaned['space_efficiency'] = df_cleaned['beds'] / df_cleaned['accommodates']\n",
    "    print(\" Created 'space_efficiency' feature\")\n",
    "\n",
    "# 5.7 Host portfolio size indicator\n",
    "if 'calculated_host_listings_count' in df_cleaned.columns:\n",
    "    df_cleaned['is_multi_listing_host'] = (df_cleaned['calculated_host_listings_count'] > 1).astype(int)\n",
    "    print(\" Created 'is_multi_listing_host' feature\")\n",
    "\n",
    "print(f\"\\n Total features after engineering: {df_cleaned.shape[1]}\")\n",
    "print(f\"\\n Note: NO review-based features created (landlord perspective only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. HANDLING MISSING VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 6.1 Drop columns with >50% missing values, EXCEPT important landlord features\n",
    "missing_threshold = 0.5\n",
    "missing_pct = df_cleaned.isnull().sum() / len(df_cleaned)\n",
    "\n",
    "# Preserve important landlord features even if they have high missing rates\n",
    "important_landlord_features = [\n",
    "    'host_response_rate', 'host_acceptance_rate', 'host_is_superhost',\n",
    "    'bedrooms', 'beds', 'bathrooms_numeric', 'price', 'accommodates',\n",
    "    'neighbourhood_cleansed', 'property_type'\n",
    "]\n",
    "\n",
    "cols_to_drop = []\n",
    "for col in missing_pct[missing_pct > missing_threshold].index:\n",
    "    if col not in important_landlord_features:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "if cols_to_drop:\n",
    "    df_cleaned = df_cleaned.drop(columns=cols_to_drop)\n",
    "    print(f\"\\n Dropped {len(cols_to_drop)} columns with >{missing_threshold*100}% missing values\")\n",
    "    print(f\"   Columns dropped: {cols_to_drop}\")\n",
    "    print(f\"   Preserved important landlord features: {important_landlord_features}\")\n",
    "\n",
    "# 6.2 Fill missing values for specific columns\n",
    "# Numeric columns - fill with median\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "\n",
    "print(f\"\\n Filled missing numeric values with median\")\n",
    "\n",
    "# Categorical columns - fill with mode or 'Unknown'\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        mode_val = df_cleaned[col].mode()\n",
    "        if len(mode_val) > 0:\n",
    "            df_cleaned[col].fillna(mode_val[0], inplace=True)\n",
    "        else:\n",
    "            df_cleaned[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(f\" Filled missing categorical values with mode or 'Unknown'\")\n",
    "\n",
    "# Check remaining missing values\n",
    "remaining_missing = df_cleaned.isnull().sum().sum()\n",
    "print(f\"\\n Remaining missing values: {remaining_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"7. OUTLIER DETECTION AND HANDLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Focus on price outliers\n",
    "if 'price' in df_cleaned.columns:\n",
    "    # Remove listings with price = 0 or extremely high prices\n",
    "    initial_rows = len(df_cleaned)\n",
    "    \n",
    "    # Remove price = 0\n",
    "    df_cleaned = df_cleaned[df_cleaned['price'] > 0]\n",
    "    \n",
    "    # Remove extreme outliers (using IQR method)\n",
    "    Q1 = df_cleaned['price'].quantile(0.25)\n",
    "    Q3 = df_cleaned['price'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 3 * IQR\n",
    "    upper_bound = Q3 + 3 * IQR\n",
    "    \n",
    "    df_cleaned = df_cleaned[(df_cleaned['price'] >= lower_bound) & \n",
    "                    (df_cleaned['price'] <= upper_bound)]\n",
    "    \n",
    "    rows_removed = initial_rows - len(df_cleaned)\n",
    "    print(f\"\\n Removed {rows_removed} rows with price outliers\")\n",
    "    print(f\"   - Price range: ${df_cleaned['price'].min():.2f} - ${df_cleaned['price'].max():.2f}\")\n",
    "    print(f\"   - Remaining rows: {len(df_cleaned):,}\")\n",
    "\n",
    "# Visualize price distribution after cleaning\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_cleaned['price'], bins=50, edgecolor='black')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price Distribution (After Outlier Removal)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df_cleaned['price'])\n",
    "plt.ylabel('Price ($)')\n",
    "plt.title('Price Boxplot (After Outlier Removal)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/price_distribution_cleaned.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Visualization saved: outputs/figures/price_distribution_cleaned.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Encode Categorical Variables (Partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. ENCODING CATEGORICAL VARIABLES (PARTIAL)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify categorical columns (excluding datetime)\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove date columns if they're still object type\n",
    "date_related = ['host_since']\n",
    "categorical_cols = [col for col in categorical_cols if col not in date_related]\n",
    "\n",
    "print(f\"\\n Categorical columns found: {len(categorical_cols)}\")\n",
    "print(f\"   Columns: {categorical_cols[:10]}...\")  # Show first 10\n",
    "\n",
    "# One-hot encode categorical variables with low cardinality\n",
    "low_cardinality_cols = []\n",
    "for col in categorical_cols:\n",
    "    if df_cleaned[col].nunique() <= 10:  # Only encode if <=10 unique values\n",
    "        low_cardinality_cols.append(col)\n",
    "\n",
    "if low_cardinality_cols:\n",
    "    df_encoded = pd.get_dummies(df_cleaned, columns=low_cardinality_cols, drop_first=True)\n",
    "    print(f\"\\n One-hot encoded {len(low_cardinality_cols)} categorical columns\")\n",
    "    print(f\"   Columns: {low_cardinality_cols}\")\n",
    "else:\n",
    "    df_encoded = df_cleaned.copy()\n",
    "\n",
    "# Keep important high-cardinality features for later encoding (T1.4)\n",
    "important_categorical = ['neighbourhood_cleansed', 'property_type']\n",
    "\n",
    "remaining_categorical = df_encoded.select_dtypes(include=['object']).columns.tolist()\n",
    "remaining_categorical = [col for col in remaining_categorical if col not in important_categorical]\n",
    "\n",
    "if remaining_categorical:\n",
    "    df_encoded = df_encoded.drop(columns=remaining_categorical)\n",
    "    print(f\"\\n Dropped {len(remaining_categorical)} high-cardinality categorical columns\")\n",
    "    print(f\"   Columns dropped: {remaining_categorical}\")\n",
    "\n",
    "# Show which important categoricals are preserved\n",
    "preserved = [col for col in important_categorical if col in df_encoded.columns]\n",
    "if preserved:\n",
    "    print(f\"\\n Preserved for T1.4 (Categorical Encoding): {preserved}\")\n",
    "\n",
    "print(f\"\\n Dataset shape after partial encoding: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Target Variable (Landlord Perspective - NO REVIEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. CREATE TARGET VARIABLE - VALUE CATEGORY (LANDLORD PERSPECTIVE)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n Using ONLY landlord-controlled features (NO review data)\")\n",
    "print(\"   Quality indicators: accommodates, beds, bathrooms, superhost, instant_bookable\\n\")\n",
    "\n",
    "# Create value category based on LANDLORD-AVAILABLE features only\n",
    "# Value = Quality indicators / Price\n",
    "# Quality indicators: accommodates, beds, bathrooms, superhost status, instant booking\n",
    "\n",
    "if 'price' in df_encoded.columns:\n",
    "    df_with_target = df_encoded.copy()\n",
    "    \n",
    "    # Calculate quality score from landlord-controlled features\n",
    "    quality_score = 0\n",
    "    \n",
    "    # Accommodation capacity (normalized)\n",
    "    if 'accommodates' in df_with_target.columns:\n",
    "        quality_score += (df_with_target['accommodates'] - df_with_target['accommodates'].min()) / \\\n",
    "                        (df_with_target['accommodates'].max() - df_with_target['accommodates'].min())\n",
    "        print(\" Added 'accommodates' to quality score\")\n",
    "    \n",
    "    # Beds (normalized)\n",
    "    if 'beds' in df_with_target.columns:\n",
    "        quality_score += (df_with_target['beds'] - df_with_target['beds'].min()) / \\\n",
    "                        (df_with_target['beds'].max() - df_with_target['beds'].min())\n",
    "        print(\" Added 'beds' to quality score\")\n",
    "    \n",
    "    # Bathrooms (normalized)\n",
    "    if 'bathrooms_numeric' in df_with_target.columns:\n",
    "        quality_score += (df_with_target['bathrooms_numeric'] - df_with_target['bathrooms_numeric'].min()) / \\\n",
    "                        (df_with_target['bathrooms_numeric'].max() - df_with_target['bathrooms_numeric'].min())\n",
    "        print(\" Added 'bathrooms_numeric' to quality score\")\n",
    "    \n",
    "    # Superhost bonus\n",
    "    if 'host_is_superhost' in df_with_target.columns:\n",
    "        quality_score += df_with_target['host_is_superhost'] * 0.5\n",
    "        print(\" Added 'host_is_superhost' bonus to quality score\")\n",
    "    \n",
    "    # Instant bookable bonus\n",
    "    if 'instant_bookable' in df_with_target.columns:\n",
    "        quality_score += df_with_target['instant_bookable'] * 0.3\n",
    "        print(\" Added 'instant_bookable' bonus to quality score\")\n",
    "    \n",
    "    # Normalize price (inverse - lower price = better value)\n",
    "    price_normalized = (df_with_target['price'] - df_with_target['price'].min()) / \\\n",
    "                      (df_with_target['price'].max() - df_with_target['price'].min())\n",
    "    \n",
    "    # Calculate FP Score (Fair Price Score) - higher quality, lower price = better value\n",
    "    df_with_target['fp_score'] = quality_score / (price_normalized + 0.1)\n",
    "    \n",
    "    # Classify into 3 categories based on FP Score\n",
    "    fp_33 = df_with_target['fp_score'].quantile(0.33)\n",
    "    fp_67 = df_with_target['fp_score'].quantile(0.67)\n",
    "    \n",
    "    def classify_value(fp_score):\n",
    "        if fp_score <= fp_33:\n",
    "            return 'Poor_Value'\n",
    "        elif fp_score <= fp_67:\n",
    "            return 'Fair_Value'\n",
    "        else:\n",
    "            return 'Excellent_Value'\n",
    "    \n",
    "    df_with_target['value_category'] = df_with_target['fp_score'].apply(classify_value)\n",
    "    \n",
    "    print(f\"\\n Created FP Score and Value Category (Landlord Perspective)\")\n",
    "    print(f\"   - Total listings: {len(df_with_target):,}\")\n",
    "    print(f\"   - FP Score range: {df_with_target['fp_score'].min():.2f} - {df_with_target['fp_score'].max():.2f}\")\n",
    "    print(f\"\\n Value Category Distribution:\")\n",
    "    print(df_with_target['value_category'].value_counts())\n",
    "    \n",
    "    # Visualize distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    df_with_target['value_category'].value_counts().plot(kind='bar', color=['red', 'orange', 'green'])\n",
    "    plt.xlabel('Value Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Value Categories (Landlord Perspective)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df_with_target['fp_score'], bins=50, edgecolor='black')\n",
    "    plt.xlabel('FP Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('FP Score Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../../outputs/figures/value_category_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n Visualization saved: outputs/figures/value_category_distribution.png\")\n",
    "    print(\"\\n NO REVIEW DATA USED - Pure landlord perspective!\")\n",
    "    \n",
    "    # Use df_with_target for further processing\n",
    "    df_final = df_with_target.copy()\n",
    "else:\n",
    "    print(\"\\n Warning: 'price' not found. Skipping target creation.\")\n",
    "    df_final = df_encoded.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prepare Features for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10. PREPARE FEATURES FOR MODELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Drop columns that shouldn't be used as features\n",
    "columns_to_exclude = [\n",
    "    'id', 'host_id', 'value_category', 'fp_score',\n",
    "    'host_since',  # Datetime column\n",
    "    # Ensure ALL review-based features are excluded (double-check)\n",
    "    'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "    'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "    'review_scores_value', 'number_of_reviews', 'number_of_reviews_ltm',\n",
    "    'number_of_reviews_l30d', 'first_review', 'last_review', 'reviews_per_month'\n",
    "]\n",
    "\n",
    "# Get feature columns (only those that exist)\n",
    "columns_to_exclude = [col for col in columns_to_exclude if col in df_final.columns]\n",
    "feature_cols = [col for col in df_final.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Separate features and target\n",
    "X = df_final[feature_cols]\n",
    "y = df_final['value_category']\n",
    "\n",
    "print(f\"\\n Features prepared (LANDLORD PERSPECTIVE ONLY)\")\n",
    "print(f\"   - Number of features: {X.shape[1]}\")\n",
    "print(f\"   - Number of samples: {X.shape[0]:,}\")\n",
    "print(f\"   - Target variable: value_category\")\n",
    "print(f\"   - Excluded columns: {len(columns_to_exclude)}\")\n",
    "print(f\"\\n Feature columns (first 20):\")\n",
    "print(X.columns.tolist()[:20])\n",
    "\n",
    "# Verify no review columns leaked through\n",
    "review_keywords = ['review', 'rating', 'score']\n",
    "leaked_features = [col for col in X.columns if any(keyword in col.lower() for keyword in review_keywords)]\n",
    "if leaked_features:\n",
    "    print(f\"\\n WARNING: Potential review-based features detected: {leaked_features}\")\n",
    "else:\n",
    "    print(f\"\\n VERIFIED: No review-based features in feature set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"11. TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n Train-test split will be performed in Task 1.6\")\n",
    "print(\"   This ensures all engineered features from T1.3, T1.4, and T1.5 are included.\")\n",
    "print(\"\\n Skipping split for now...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Scaling (Deferred to T1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"12. FEATURE SCALING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n Feature scaling will be performed in Task 1.6 (Train-Test Split & Scaling)\")\n",
    "print(\"   This ensures all engineered features from T1.3, T1.4, and T1.5 are included.\")\n",
    "print(\"\\n Saving UNSCALED data for now...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"13. SAVE PROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('../../data/processed', exist_ok=True)\n",
    "\n",
    "# Save cleaned full dataset\n",
    "df_final.to_csv('../../data/processed/listings_cleaned_with_target.csv', index=False)\n",
    "print(\"\\n Saved: data/processed/listings_cleaned_with_target.csv\")\n",
    "print(f\"   - Shape: {df_final.shape}\")\n",
    "print(f\"   - Columns: {df_final.shape[1]}\")\n",
    "\n",
    "# Save feature names (for reference)\n",
    "feature_cols = [col for col in df_final.columns if col not in ['id', 'host_id', 'value_category', 'fp_score', 'host_since']]\n",
    "with open('../../outputs/reports/feature_names_T1.2.txt', 'w') as f:\n",
    "    for feature in feature_cols:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "\n",
    "print(\"✓ Saved: outputs/reports/feature_names_T1.2.txt\")\n",
    "print(f\"   - Features: {len(feature_cols)}\")\n",
    "\n",
    "print(\"\\n Note: Train-test split will be done in T1.6 after all feature engineering (T1.3, T1.4, T1.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"14. PREPROCESSING SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "DATA PREPROCESSING COMPLETED SUCCESSFULLY (LANDLORD PERSPECTIVE)\n",
    "{'='*80}\n",
    "\n",
    "ORIGINAL DATA:\n",
    "  - San Francisco: 7,780 listings\n",
    "  - San Diego: 13,162 listings\n",
    "  - Combined: {df.shape[0]:,} listings, {df.shape[1]} columns\n",
    "\n",
    "AFTER CLEANING:\n",
    "  - Final dataset: {df_final.shape[0]:,} listings, {df_final.shape[1]} columns\n",
    "  - Features preserved: {df_final.shape[1]}\n",
    "\n",
    "TARGET VARIABLE:\n",
    "  - Name: value_category\n",
    "  - Classes: Poor_Value, Fair_Value, Excellent_Value\n",
    "  - Based on: Landlord-controlled features ONLY (NO REVIEWS)\n",
    "  - Quality indicators: accommodates, beds, bathrooms, superhost, instant_bookable\n",
    "  - Distribution:\n",
    "{df_final['value_category'].value_counts().to_string()}\n",
    "\n",
    "KEY STEPS PERFORMED:\n",
    "   Removed irrelevant columns (URLs, IDs, text descriptions)\n",
    "   REMOVED ALL REVIEW-BASED FEATURES (data leakage prevention)\n",
    "   Converted data types (price, percentages, booleans, dates)\n",
    "   Feature engineering (host_years, price_per_person, etc.) - LANDLORD ONLY\n",
    "   Handled missing values (preserved important landlord features)\n",
    "   Removed outliers (price outliers using IQR method)\n",
    "   Encoded categorical variables (partial - low cardinality only)\n",
    "   Created target variable (FP Score - LANDLORD PERSPECTIVE)\n",
    "   Train-test split deferred to T1.6 (after all feature engineering)\n",
    "\n",
    "OUTPUT FILES:\n",
    "  - data/processed/listings_cleaned_with_target.csv\n",
    "  - data/processed/feature_names_T1.2.txt\n",
    "\n",
    "VISUALIZATIONS:\n",
    "  - outputs/figures/missing_values_analysis.png\n",
    "  - outputs/figures/price_distribution_cleaned.png\n",
    "  - outputs/figures/value_category_distribution.png\n",
    "\n",
    "CRITICAL NOTES:\n",
    "   NO REVIEW DATA USED - Pure landlord perspective\n",
    "   All review-based features excluded to prevent data leakage\n",
    "   Target based on features available at listing creation time\n",
    "   neighbourhood_cleansed and property_type preserved for T1.4\n",
    "   Train-test split will be performed in T1.6\n",
    "\n",
    "NEXT STEP:\n",
    "  Task 1.3: Algebraic Feature Engineering\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary to file\n",
    "import os\n",
    "os.makedirs('../../outputs/reports', exist_ok=True)\n",
    "with open('../../outputs/reports/T1.2_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\nSummary saved to: outputs/reports/T1.2_summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
