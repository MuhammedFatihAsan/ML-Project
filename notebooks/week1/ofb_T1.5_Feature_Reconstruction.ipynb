{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Landlord-Controlled Feature Reconstruction\n",
    "\n",
    "## Critical Issue Identified\n",
    "\n",
    "**Problem**: Our current model includes features derived from guest reviews and booking historyâ€”data that doesn't exist when a landlord first posts a listing. This creates a fundamental logical flaw:\n",
    "\n",
    "- We're predicting \"value category\" (Poor/Fair/Excellent)\n",
    "- Value is calculated as: `FP Score = Rating / Price`\n",
    "- But we're using `review_scores_rating` as a feature to predict the category\n",
    "- **This is circular logic**: We were using reviews to predict a label created from reviews\n",
    "\n",
    "## The Two-Stage Process\n",
    "\n",
    "### Stage 1: Label Creation (Historical Data)\n",
    "```\n",
    "Input: Existing listings with reviews\n",
    "Calculate: FP Score = review_scores_rating / price\n",
    "Output: value_category (Poor/Fair/Excellent)\n",
    "```\n",
    "\n",
    "### Stage 2: Model Training (Prediction)\n",
    "```\n",
    "Input: ONLY landlord-controlled features (no reviews)\n",
    "Predict: value_category\n",
    "Goal: \"Will this NEW listing be good value?\"\n",
    "```\n",
    "\n",
    "## Real-World Use Case\n",
    "\n",
    "A landlord wants to list a new property and asks:\n",
    "> \"Given my property features and the price I'm setting, will guests consider this good value?\"\n",
    "\n",
    "The model should answer this using ONLY information available at posting time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data\n",
    "\n",
    "We'll load the full dataset with categorical encoding to access all available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Create output directories\n",
    "Path('../../data/processed').mkdir(parents=True, exist_ok=True)\n",
    "Path('../../outputs').mkdir(parents=True, exist_ok=True)\n",
    "Path('../../outputs/figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LANDLORD-CONTROLLED FEATURE RECONSTRUCTION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nLibraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "print(\"\\nLoading dataset with categorical encoding...\")\n",
    "df = pd.read_csv('../../data/processed/listings_with_categorical_encoding.csv')\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"  Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst few columns: {df.columns.tolist()[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Categorize All Features\n",
    "\n",
    "We'll systematically categorize every feature into three groups:\n",
    "\n",
    "### 1.  Landlord-Controlled (Keep)\n",
    "Features the landlord sets when posting the listing:\n",
    "- Property characteristics (beds, bedrooms, bathrooms)\n",
    "- Location (latitude, longitude, neighborhood)\n",
    "- Pricing (price, minimum_nights)\n",
    "- Availability settings\n",
    "- Host profile information\n",
    "\n",
    "### 2.  Review-Based (Remove)\n",
    "Features that require guest reviews/bookings:\n",
    "- All `review_scores_*` columns\n",
    "- `number_of_reviews*` columns\n",
    "- Review dates and derived features\n",
    "- Estimated occupancy/revenue (requires booking history)\n",
    "\n",
    "### 3.  Target-Related (Remove)\n",
    "Features used to create or directly related to the target:\n",
    "- `fp_score`, `value_category`\n",
    "- `rating_normalized`, `price_normalized` (if present)\n",
    "\n",
    "### 4.  Identifiers (Remove for modeling)\n",
    "- `id`, `host_id` (keep for merging, remove for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature categories\n",
    "\n",
    "#  LANDLORD-CONTROLLED FEATURES\n",
    "landlord_features = [\n",
    "    # Property Characteristics\n",
    "    'accommodates', 'bedrooms', 'beds', 'bathrooms_numeric',\n",
    "    \n",
    "    # Pricing (KEEP - essential for value prediction)\n",
    "    'price', 'price_per_person',\n",
    "    \n",
    "    # Location\n",
    "    'latitude', 'longitude',\n",
    "    \n",
    "    # Booking Rules\n",
    "    'minimum_nights', 'maximum_nights',\n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights',\n",
    "    'minimum_maximum_nights', 'maximum_maximum_nights',\n",
    "    'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm',\n",
    "    \n",
    "    # Availability Settings\n",
    "    'has_availability', 'availability_30', 'availability_60',\n",
    "    'availability_90', 'availability_365', 'availability_rate',\n",
    "    \n",
    "    # Host Profile\n",
    "    'host_response_rate', 'host_acceptance_rate',\n",
    "    'host_is_superhost', 'host_listings_count',\n",
    "    'host_total_listings_count', 'host_has_profile_pic',\n",
    "    'host_identity_verified', 'host_years',\n",
    "    \n",
    "    # Booking Options\n",
    "    'instant_bookable',\n",
    "    \n",
    "    # Categorical Encodings (from Task 1.4)\n",
    "    # Room type one-hot encoded columns\n",
    "    'room_type_Hotel room', 'room_type_Private room', 'room_type_Shared room',\n",
    "    \n",
    "    # Property type encodings\n",
    "    'property_type_label', 'property_type_frequency',\n",
    "    \n",
    "    # Neighborhood encodings\n",
    "    'neighbourhood_target_encoded', 'neighbourhood_frequency',\n",
    "    'neighbourhood_label',\n",
    "    \n",
    "    # Host response time (one-hot encoded)\n",
    "    'host_response_time_within a day',\n",
    "    'host_response_time_within a few hours',\n",
    "    'host_response_time_within an hour',\n",
    "    \n",
    "    # Calculated host listings\n",
    "    'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_entire_homes',\n",
    "    'calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms'\n",
    "]\n",
    "\n",
    "#  REVIEW-BASED FEATURES (Remove)\n",
    "review_features = [\n",
    "    # Review Scores\n",
    "    'review_scores_rating', 'review_scores_accuracy',\n",
    "    'review_scores_cleanliness', 'review_scores_checkin',\n",
    "    'review_scores_communication', 'review_scores_location',\n",
    "    'review_scores_value', 'avg_review_score',\n",
    "    \n",
    "    # Review Counts\n",
    "    'number_of_reviews', 'number_of_reviews_ltm',\n",
    "    'number_of_reviews_l30d', 'reviews_per_month',\n",
    "    'has_reviews',\n",
    "    \n",
    "    # Review Dates\n",
    "    'first_review', 'last_review',\n",
    "    'days_since_first_review', 'days_since_last_review',\n",
    "    \n",
    "    # Booking History\n",
    "    'estimated_occupancy_l365d', 'estimated_revenue_l365d',\n",
    "    'availability_eoy', 'number_of_reviews_ly'\n",
    "]\n",
    "\n",
    "#  TARGET-RELATED FEATURES (Remove)\n",
    "target_features = [\n",
    "    'fp_score', 'value_category', 'value_encoded',\n",
    "    'rating_normalized', 'price_normalized'\n",
    "]\n",
    "\n",
    "# ðŸ—‘ï¸ IDENTIFIER COLUMNS (Keep for merging, remove for training)\n",
    "id_columns = ['id', 'host_id']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE CATEGORIZATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n Landlord-Controlled Features: {len(landlord_features)}\")\n",
    "print(f\" Review-Based Features: {len(review_features)}\")\n",
    "print(f\"  Target-Related Features: {len(target_features)}\")\n",
    "print(f\"  Identifier Columns: {len(id_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Feature Availability\n",
    "\n",
    "Check which features from our categorization actually exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which features exist in the dataset\n",
    "available_landlord = [f for f in landlord_features if f in df.columns]\n",
    "available_review = [f for f in review_features if f in df.columns]\n",
    "available_target = [f for f in target_features if f in df.columns]\n",
    "available_ids = [f for f in id_columns if f in df.columns]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE AVAILABILITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n Available Landlord Features: {len(available_landlord)}/{len(landlord_features)}\")\n",
    "missing_landlord = set(landlord_features) - set(available_landlord)\n",
    "if missing_landlord:\n",
    "    print(f\"   Missing: {missing_landlord}\")\n",
    "\n",
    "print(f\"\\n Available Review Features: {len(available_review)}/{len(review_features)}\")\n",
    "print(f\"   These will be REMOVED from the model\")\n",
    "\n",
    "print(f\"\\n  Available Target Features: {len(available_target)}/{len(target_features)}\")\n",
    "print(f\"   These will be REMOVED from features (kept as target)\")\n",
    "\n",
    "print(f\"\\n  Available ID Columns: {len(available_ids)}/{len(id_columns)}\")\n",
    "print(f\"   These will be kept for merging but removed for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Clean Feature Set\n",
    "\n",
    "Now we'll create the final dataset with:\n",
    "1. All landlord-controlled features\n",
    "2. ID columns (for merging with NLP features later)\n",
    "3. Target variable (`value_category`)\n",
    "4. NO review-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the clean feature set\n",
    "features_to_keep = available_ids + available_landlord + ['value_category']\n",
    "\n",
    "# Filter to only existing columns\n",
    "features_to_keep = [f for f in features_to_keep if f in df.columns]\n",
    "\n",
    "# Create clean dataset\n",
    "df_clean = df[features_to_keep].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLEAN DATASET CREATED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOriginal dataset: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"Clean dataset: {df_clean.shape[0]:,} rows Ã— {df_clean.shape[1]} columns\")\n",
    "print(f\"\\nFeatures removed: {df.shape[1] - df_clean.shape[1]}\")\n",
    "print(f\"Features retained: {df_clean.shape[1] - 1} (excluding target)\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_counts = df_clean.isnull().sum()\n",
    "cols_with_missing = missing_counts[missing_counts > 0]\n",
    "\n",
    "if len(cols_with_missing) > 0:\n",
    "    print(f\"\\n  Warning: {len(cols_with_missing)} columns have missing values\")\n",
    "    print(\"\\nTop 10 columns with missing values:\")\n",
    "    print(cols_with_missing.sort_values(ascending=False).head(10))\n",
    "else:\n",
    "    print(\"\\n No missing values in the clean dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Feature Summary Statistics\n",
    "\n",
    "Let's examine the distribution of our landlord-controlled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical features\n",
    "numerical_features = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features = [f for f in numerical_features if f not in available_ids + ['value_category']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NUMERICAL FEATURES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal numerical features: {len(numerical_features)}\")\n",
    "\n",
    "# Display summary statistics\n",
    "summary_stats = df_clean[numerical_features].describe().T\n",
    "summary_stats['missing'] = df_clean[numerical_features].isnull().sum()\n",
    "summary_stats['missing_pct'] = (summary_stats['missing'] / len(df_clean) * 100).round(2)\n",
    "\n",
    "print(\"\\nKey features summary:\")\n",
    "key_features = ['price', 'accommodates', 'bedrooms', 'beds', 'bathrooms_numeric',\n",
    "                'availability_365', 'minimum_nights', 'host_years']\n",
    "key_features = [f for f in key_features if f in numerical_features]\n",
    "\n",
    "print(summary_stats.loc[key_features, ['mean', 'std', 'min', '50%', 'max', 'missing']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Feature Distributions\n",
    "\n",
    "Create visualizations to understand our landlord-controlled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of key features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "key_viz_features = ['price', 'accommodates', 'bedrooms', 'beds', \n",
    "                    'bathrooms_numeric', 'availability_365']\n",
    "key_viz_features = [f for f in key_viz_features if f in df_clean.columns]\n",
    "\n",
    "for idx, feature in enumerate(key_viz_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Filter outliers for better visualization\n",
    "    data = df_clean[feature].dropna()\n",
    "    q99 = data.quantile(0.99)\n",
    "    data_filtered = data[data <= q99]\n",
    "    \n",
    "    ax.hist(data_filtered, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax.set_xlabel(feature.replace('_', ' ').title(), fontsize=11)\n",
    "    ax.set_ylabel('Frequency', fontsize=11)\n",
    "    ax.set_title(f'{feature.replace(\"_\", \" \").title()} Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = data_filtered.mean()\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.1f}')\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Landlord-Controlled Features Distribution', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/landlord_features_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Saved: outputs/figures/landlord_features_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Target Variable Distribution\n",
    "\n",
    "Verify that our target variable is still balanced after feature filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distribution\n",
    "target_dist = df_clean['value_category'].value_counts().sort_index()\n",
    "target_pct = (target_dist / len(df_clean) * 100).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nValue Category Distribution:\")\n",
    "for category, count in target_dist.items():\n",
    "    pct = target_pct[category]\n",
    "    print(f\"  {category}: {count:,} ({pct}%)\")\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = {'Excellent_Value': '#2ecc71', 'Fair_Value': '#f1c40f', 'Poor_Value': '#e74c3c'}\n",
    "bars = ax.bar(target_dist.index, target_dist.values, \n",
    "              color=[colors.get(x, 'gray') for x in target_dist.index],\n",
    "              edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add percentage labels\n",
    "for bar, pct in zip(bars, target_pct.values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{pct}%',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Value Category', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Count', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Target Variable Distribution (Landlord-Controlled Features Only)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/figures/target_distribution_clean.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Saved: outputs/figures/target_distribution_clean.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Clean Dataset\n",
    "\n",
    "Save the cleaned dataset with only landlord-controlled features for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean dataset\n",
    "output_path = '../../data/processed/listings_landlord_features_only.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET SAVED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nâœ… Saved: {output_path}\")\n",
    "print(f\"   Shape: {df_clean.shape[0]:,} rows Ã— {df_clean.shape[1]} columns\")\n",
    "print(f\"   Features (excluding ID and target): {df_clean.shape[1] - len(available_ids) - 1}\")\n",
    "\n",
    "# Save feature list for reference\n",
    "feature_list = [f for f in df_clean.columns if f not in available_ids + ['value_category']]\n",
    "feature_df = pd.DataFrame({\n",
    "    'feature_name': feature_list,\n",
    "    'data_type': [df_clean[f].dtype for f in feature_list],\n",
    "    'missing_count': [df_clean[f].isnull().sum() for f in feature_list],\n",
    "    'missing_pct': [(df_clean[f].isnull().sum() / len(df_clean) * 100).round(2) for f in feature_list]\n",
    "})\n",
    "\n",
    "feature_list_path = '../../outputs/landlord_features_list.csv'\n",
    "feature_df.to_csv(feature_list_path, index=False)\n",
    "print(f\"\\n Saved feature list: {feature_list_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Create Train-Test Split\n",
    "\n",
    "Split the clean dataset for model training, maintaining the same 80-20 split with stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Separate features and target\n",
    "X = df_clean.drop(columns=['value_category'] + available_ids)\n",
    "y = df_clean['value_category']\n",
    "ids = df_clean[available_ids]\n",
    "\n",
    "# Train-test split (80-20, stratified)\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X, y, ids, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTraining set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Feature Scaling\n",
    "\n",
    "Apply StandardScaler to normalize features for algorithms sensitive to feature scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n Features scaled using StandardScaler\")\n",
    "print(f\"   Training set shape: {X_train_scaled_df.shape}\")\n",
    "print(f\"   Test set shape: {X_test_scaled_df.shape}\")\n",
    "\n",
    "# Verify scaling\n",
    "print(f\"\\nScaling verification (training set):\")\n",
    "print(f\"   Mean (should be ~0): {X_train_scaled_df.mean().mean():.6f}\")\n",
    "print(f\"   Std (should be ~1): {X_train_scaled_df.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Save Processed Data\n",
    "\n",
    "Save all processed datasets for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unscaled data\n",
    "X_train.to_csv('../../data/processed/X_train_landlord.csv', index=False)\n",
    "X_test.to_csv('../../data/processed/X_test_landlord.csv', index=False)\n",
    "y_train.to_csv('../../data/processed/y_train_landlord.csv', index=False, header=True)\n",
    "y_test.to_csv('../../data/processed/y_test_landlord.csv', index=False, header=True)\n",
    "\n",
    "# Save scaled data\n",
    "X_train_scaled_df.to_csv('../../data/processed/X_train_scaled_landlord.csv', index=False)\n",
    "X_test_scaled_df.to_csv('../../data/processed/X_test_scaled_landlord.csv', index=False)\n",
    "\n",
    "# Save IDs for merging with NLP features later\n",
    "ids_train.to_csv('../../data/processed/train_ids.csv', index=False)\n",
    "ids_test.to_csv('../../data/processed/test_ids.csv', index=False)\n",
    "\n",
    "# Save scaler\n",
    "with open('../../models/scaler_landlord.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL FILES SAVED\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n Unscaled Data:\")\n",
    "print(\"    data/processed/X_train_landlord.csv\")\n",
    "print(\"    data/processed/X_test_landlord.csv\")\n",
    "print(\"    data/processed/y_train_landlord.csv\")\n",
    "print(\"    data/processed/y_test_landlord.csv\")\n",
    "print(\"\\n Scaled Data:\")\n",
    "print(\"    data/processed/X_train_scaled_landlord.csv\")\n",
    "print(\"    data/processed/X_test_scaled_landlord.csv\")\n",
    "print(\"\\n Supporting Files:\")\n",
    "print(\"    data/processed/train_ids.csv (for NLP merging)\")\n",
    "print(\"    data/processed/test_ids.csv (for NLP merging)\")\n",
    "print(\"    models/scaler_landlord.pkl\")\n",
    "print(\"    outputs/landlord_features_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Summary Report\n",
    "\n",
    "Generate a comprehensive summary of the feature reconstruction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LANDLORD-CONTROLLED FEATURE RECONSTRUCTION - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_report = f\"\"\"\n",
    "## Problem Identified\n",
    "Original model included review-based features (review_scores_rating, \n",
    "number_of_reviews, etc.) which are not available when a landlord first \n",
    "posts a listing. This created circular logic since these features were \n",
    "used to predict labels created from those same features.\n",
    "\n",
    "## Solution Implemented\n",
    "Rebuilt feature set to include ONLY landlord-controlled features:\n",
    "- Property characteristics (beds, bedrooms, bathrooms, accommodates)\n",
    "- Location (latitude, longitude, neighborhood encodings)\n",
    "- Pricing (price, price_per_person) â† KEPT as essential\n",
    "- Booking rules (minimum_nights, availability settings)\n",
    "- Host profile (host_years, superhost status, response rates)\n",
    "\n",
    "## Data Summary\n",
    "Original dataset: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\n",
    "Clean dataset: {df_clean.shape[0]:,} rows Ã— {df_clean.shape[1]} columns\n",
    "Features removed: {df.shape[1] - df_clean.shape[1]}\n",
    "Features retained: {X_train.shape[1]} (for modeling)\n",
    "\n",
    "Training samples: {X_train.shape[0]:,} ({X_train.shape[0]/len(X)*100:.1f}%)\n",
    "Test samples: {X_test.shape[0]:,} ({X_test.shape[0]/len(X)*100:.1f}%)\n",
    "\n",
    "## Target Distribution (Balanced)\n",
    "{y.value_counts().sort_index().to_string()}\n",
    "\n",
    "## Key Features Included\n",
    " price (essential for value prediction)\n",
    " accommodates, bedrooms, beds, bathrooms_numeric\n",
    " latitude, longitude, neighborhood encodings\n",
    " availability_365, minimum_nights\n",
    " host_years, host_is_superhost\n",
    "âœ…room_type encodings, property_type encodings\n",
    "\n",
    "## Features REMOVED (Review-Based)\n",
    " review_scores_* (all review score columns)\n",
    " number_of_reviews* (all review count columns)\n",
    " estimated_occupancy_l365d, estimated_revenue_l365d\n",
    " first_review, last_review, days_since_*_review\n",
    "\n",
    "## Expected Model Performance\n",
    "Previous accuracy with reviews: ~99% (circular logic)\n",
    "Expected accuracy without reviews: ~65-75% (realistic)\n",
    "\n",
    "The lower accuracy is CORRECT because:\n",
    "1. We're predicting future value without knowing future reviews\n",
    "2. The model must learn from property features alone\n",
    "3. This matches real-world use case (new listing prediction)\n",
    "\n",
    "## Next Steps\n",
    "1. Retrain all models (Logistic Regression, Random Forest, XGBoost, SVM, MLP)\n",
    "2. Compare performance with landlord-only features\n",
    "3. Add NLP features from listing descriptions (optional enhancement)\n",
    "4. Evaluate realistic model performance\n",
    "\n",
    "## Files Generated\n",
    " listings_landlord_features_only.csv - Full clean dataset\n",
    " X_train_landlord.csv, X_test_landlord.csv - Unscaled splits\n",
    " X_train_scaled_landlord.csv, X_test_scaled_landlord.csv - Scaled splits\n",
    " y_train_landlord.csv, y_test_landlord.csv - Target variables\n",
    " train_ids.csv, test_ids.csv - IDs for NLP merging\n",
    " scaler_landlord.pkl - Fitted scaler for deployment\n",
    " landlord_features_list.csv - Feature documentation\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save summary report\n",
    "with open('../../outputs/reports/landlord_features_reconstruction_summary.txt', 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"\\n Summary saved: outputs/landlord_features_reconstruction_summary.txt\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK COMPLETE - Ready for Model Retraining\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We have successfully reconstructed our feature set to include only landlord-controlled variables. This ensures our model can make realistic predictions for NEW listings where review data doesn't exist yet.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Price is NOT leakage** - It's an essential input that landlords control\n",
    "2. **Review features ARE leakage** - They don't exist for new listings\n",
    "3. **Lower accuracy is expected** - We're solving a harder, more realistic problem\n",
    "4. **Model is now deployable** - Can predict value for any new listing\n",
    "\n",
    "### Real-World Application\n",
    "\n",
    "A landlord can now input:\n",
    "- Property details (beds, bathrooms, location)\n",
    "- Desired price\n",
    "- Booking rules\n",
    "\n",
    "And receive a prediction:\n",
    "> \"Based on similar properties in your area, this listing will likely be considered **Fair Value** by guests.\"\n",
    "\n",
    "This is actionable intelligence that helps landlords optimize their pricing strategy BEFORE receiving any reviews."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
